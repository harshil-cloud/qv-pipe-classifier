{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Étape 3 – Entraînement baseline sur super-images 3×3 (Colab Pro+)\n",
        "\n",
        "Ce notebook entraîne un classifieur multi-label sur des super-images 3×3 construites à partir de 9 frames par vidéo.\n",
        "La logique d’entraînement est la même que pour l’Étape 2 (baseline framewise) :\n",
        "\n",
        "- Le code est dans `/content/qv-pipe-classifier`\n",
        "- Les données (CSV + super-images) sont sur Google Drive\n",
        "- Les modèles entraînés et l’historique sont sauvegardés dans `.../models/super_images_convnext`\n"
      ],
      "metadata": {
        "id": "UEnXMNAhFmPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vérifier le GPU Colab disponible\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "bQXOJR2qFr9v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd56293e-d7e1-461d-a496-5f5949e79756"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Nov 30 19:36:35 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0             52W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Monter Google Drive (données + sorties des modèles)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "0MtVXvVuFwW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddbf61a7-9996-4f6b-b7f7-a9c450ba8ab5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cloner dépôt dans /content"
      ],
      "metadata": {
        "id": "svxfbz8hZ7Rp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clonage du dépôt dans /content (première fois dans cette session)\n",
        "%cd /content\n",
        "\n",
        "!git clone https://github.com/Simon-VDC/qv-pipe-classifier.git\n",
        "%cd qv-pipe-classifier\n",
        "\n",
        "!ls\n"
      ],
      "metadata": {
        "id": "bsR6NQxAFzJJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f202d07-a9dc-4ff0-efe6-53c20c1434c6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'qv-pipe-classifier'...\n",
            "remote: Enumerating objects: 412, done.\u001b[K\n",
            "remote: Counting objects: 100% (244/244), done.\u001b[K\n",
            "remote: Compressing objects: 100% (208/208), done.\u001b[K\n",
            "remote: Total 412 (delta 121), reused 119 (delta 28), pack-reused 168 (from 1)\u001b[K\n",
            "Receiving objects: 100% (412/412), 863.59 KiB | 10.16 MiB/s, done.\n",
            "Resolving deltas: 100% (206/206), done.\n",
            "/content/qv-pipe-classifier\n",
            "CONFIG.md      docs\t\texp\t   project_tree.txt  requirements\n",
            "data\t       ENVIRONMENT.md\tLICENSE    README.md\t     scripts\n",
            "DATA_NOTES.md  environment.yml\tnotebooks  reports\t     src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Si le dépôt est déjà cloné, le mettre à jour\n",
        "%cd /content/qv-pipe-classifier\n",
        "!git pull"
      ],
      "metadata": {
        "id": "DnqmkH_sIjMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcd01c2a-0f4f-4183-d783-32a1a99b1694"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/qv-pipe-classifier\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 9 (delta 7), reused 5 (delta 4), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (9/9), 1.75 KiB | 446.00 KiB/s, done.\n",
            "From https://github.com/Simon-VDC/qv-pipe-classifier\n",
            "   41abf97..f4ce07e  main       -> origin/main\n",
            "Updating 41abf97..f4ce07e\n",
            "Fast-forward\n",
            " notebooks/03_train_superimages.ipynb       | 71 \u001b[32m++++++++++++++++++++++++++++\u001b[m\u001b[31m--\u001b[m\n",
            " src/train/super_images_baseline_CBfocal.py |  8 \u001b[32m++\u001b[m\u001b[31m--\u001b[m\n",
            " 2 files changed, 71 insertions(+), 8 deletions(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation des dépendances"
      ],
      "metadata": {
        "id": "_SED-fu_Z3Tk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installer les dépendances Step 2\n",
        "!pip install -r requirements/step3_training.txt\n"
      ],
      "metadata": {
        "id": "qBCmoMkxI1XN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96af3807-afad-4447-f413-081eff2877e5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements/step3_training.txt (line 2)) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from -r requirements/step3_training.txt (line 3)) (0.24.0+cu126)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (from -r requirements/step3_training.txt (line 4)) (1.0.22)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements/step3_training.txt (line 5)) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements/step3_training.txt (line 6)) (2.2.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from -r requirements/step3_training.txt (line 7)) (11.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r requirements/step3_training.txt (line 8)) (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (3.5.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm->-r requirements/step3_training.txt (line 4)) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm->-r requirements/step3_training.txt (line 4)) (0.36.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm->-r requirements/step3_training.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements/step3_training.txt (line 6)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements/step3_training.txt (line 6)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements/step3_training.txt (line 6)) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements/step3_training.txt (line 8)) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements/step3_training.txt (line 8)) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements/step3_training.txt (line 8)) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements/step3_training.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r requirements/step3_training.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm->-r requirements/step3_training.txt (line 4)) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm->-r requirements/step3_training.txt (line 4)) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm->-r requirements/step3_training.txt (line 4)) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm->-r requirements/step3_training.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r requirements/step3_training.txt (line 2)) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm->-r requirements/step3_training.txt (line 4)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm->-r requirements/step3_training.txt (line 4)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm->-r requirements/step3_training.txt (line 4)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm->-r requirements/step3_training.txt (line 4)) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration des dossiers de données et de modèles\n",
        "\n",
        "Les données (CSV + super-images) sont stockées sur Google Drive.  \n",
        "Les modèles entraînés et l’historique pour l’Étape 3 seront sauvegardés dans :\n",
        "\n",
        "- `models/super_images_convnext/fold_*/best.pth`\n",
        "- `models/super_images_convnext/fold_*/history.json`"
      ],
      "metadata": {
        "id": "9hhPOLN1ZwMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Dossier racine des données sur Google Drive\n",
        "DATA_BASE_DIR = \"/content/drive/MyDrive/QV Pipe\"  # adapter si nécessaire\n",
        "\n",
        "# CSV des splits pour les super-images (doit contenir : video_stem, superimage_path, labels_str, fold)\n",
        "SPLITS_CSV = os.path.join(DATA_BASE_DIR, \"data/splits/super_images_3x3_folds_colab.csv\")\n",
        "\n",
        "# Dossier de sortie pour les modèles et l'historique (même logique que baseline Étape 2)\n",
        "MODELS_DIR = os.path.join(DATA_BASE_DIR, \"models/super_images_convnext\")\n",
        "\n",
        "print(\"SPLITS_CSV:\", SPLITS_CSV)\n",
        "print(\"MODELS_DIR:\", MODELS_DIR)\n"
      ],
      "metadata": {
        "id": "rBoisAN2I_M3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "612358d2-9090-4f9f-c147-3100eb7b701e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SPLITS_CSV: /content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\n",
            "MODELS_DIR: /content/drive/MyDrive/QV Pipe/models/super_images_convnext\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correction du fichier splits pour colab"
      ],
      "metadata": {
        "id": "tunSGWAWeMwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Chemin du CSV original (celui que tu utilises actuellement)\n",
        "DATA_BASE_DIR = \"/content/drive/MyDrive/QV Pipe\"  # adapte si besoin\n",
        "ORIG_CSV = os.path.join(DATA_BASE_DIR, \"data/splits/super_images_3x3_folds.csv\")\n",
        "\n",
        "df = pd.read_csv(ORIG_CSV)\n",
        "print(\"Avant correction:\", df.loc[0, \"superimage_path\"])\n",
        "\n",
        "# 1) Si les chemins sont relatifs \"data/super_images/....\"\n",
        "# 2) Si le vrai dossier sur Drive est \"data/super_images_3x3\"\n",
        "#    et que tu veux des chemins ABSOLUS pour Colab\n",
        "\n",
        "def fix_path(p):\n",
        "    # remplace le dossier si besoin\n",
        "    p = str(p).replace(\"data/super_images/\", \"data/super_images_3x3/\")\n",
        "    # préfixe par le chemin de base sur le Drive\n",
        "    full = os.path.join(DATA_BASE_DIR, p)\n",
        "    return full\n",
        "\n",
        "df[\"superimage_path\"] = df[\"superimage_path\"].apply(fix_path)\n",
        "\n",
        "print(\"Après correction:\", df.loc[0, \"superimage_path\"])\n",
        "print(\"Existe sur le disque :\", os.path.exists(df.loc[0, \"superimage_path\"]))\n",
        "\n",
        "# Sauvegarde dans un nouveau CSV spécifique à Colab\n",
        "FIXED_CSV = os.path.join(DATA_BASE_DIR, \"data/splits/super_images_3x3_folds_colab.csv\")\n",
        "df.to_csv(FIXED_CSV, index=False)\n",
        "\n",
        "print(\"CSV corrigé sauvegardé dans :\", FIXED_CSV)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP2o__QweP0K",
        "outputId": "979c0cdc-7e82-4011-c639-fa2e429aa411"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avant correction: data/super_images/2019_3x3.jpg\n",
            "Après correction: /content/drive/MyDrive/QV Pipe/data/super_images_3x3/2019_3x3.jpg\n",
            "Existe sur le disque : True\n",
            "CSV corrigé sauvegardé dans : /content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vérification rapide du CSV de splits\n",
        "\n",
        "\n",
        "Vérifier que :\n",
        "- Le fichier CSV existe\n",
        "- La colonne `superimage_path` contient des chemins valides vers des fichiers PNG/JPEG stockés sur Google Drive"
      ],
      "metadata": {
        "id": "ZuNZGFg8aMK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "assert os.path.exists(SPLITS_CSV), f\"Fichier CSV introuvable : {SPLITS_CSV}\"\n",
        "\n",
        "df = pd.read_csv(SPLITS_CSV)\n",
        "print(\"CSV chargé, shape :\", df.shape)\n",
        "print(df.head())\n",
        "\n",
        "# Optionnel : vérifier le premier chemin d’image\n",
        "first_path = df.loc[0, \"superimage_path\"]\n",
        "print(\"Exemple de superimage_path :\", first_path)\n",
        "print(\"Existe sur le disque :\", os.path.exists(first_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfXNKgJ9aP81",
        "outputId": "b4f64267-6a95-421c-b1fc-1862f7cef1dd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV chargé, shape : (2881, 4)\n",
            "  video_stem                                    superimage_path labels_str  \\\n",
            "0       2019  /content/drive/MyDrive/QV Pipe/data/super_imag...          0   \n",
            "1        202  /content/drive/MyDrive/QV Pipe/data/super_imag...          0   \n",
            "2       2022  /content/drive/MyDrive/QV Pipe/data/super_imag...          0   \n",
            "3       2023  /content/drive/MyDrive/QV Pipe/data/super_imag...          0   \n",
            "4       2036  /content/drive/MyDrive/QV Pipe/data/super_imag...          0   \n",
            "\n",
            "   fold  \n",
            "0     0  \n",
            "1     4  \n",
            "2     2  \n",
            "3     2  \n",
            "4     0  \n",
            "Exemple de superimage_path : /content/drive/MyDrive/QV Pipe/data/super_images_3x3/2019_3x3.jpg\n",
            "Existe sur le disque : True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vérifier la disponibilité du GPU\n",
        "\n",
        "Vérifier que Colab utilise un GPU et afficher son nom.\n"
      ],
      "metadata": {
        "id": "-JRYThoSabGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(\"CUDA disponible :\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU :\", torch.cuda.get_device_name(0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xd1F2K8MafuO",
        "outputId": "de2b0167-9975-47a4-a8f6-1aeedb7938bd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA disponible : True\n",
            "GPU : NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dry run sur 1 fold (test rapide)\n",
        "\n",
        "Lancer un entraînement court (peu d’epochs, petit batch) sur un seul fold pour valider :\n",
        "- Le chargement des données depuis `super_images_3x3_folds.csv`\n",
        "- Le forward/backward du modèle\n",
        "- Le calcul de la loss et de la mAP\n",
        "- La sauvegarde du checkpoint et de l’historique dans `MODELS_DIR`"
      ],
      "metadata": {
        "id": "8tpr61N1JBDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/qv-pipe-classifier\n",
        "\n",
        "!python -m src.train.super_images_baseline \\\n",
        "  --splits_csv \"{SPLITS_CSV}\" \\\n",
        "  --models_dir \"{MODELS_DIR}\" \\\n",
        "  --fold 0 \\\n",
        "  --epochs 2 \\\n",
        "  --batch_size 2 \\\n",
        "  --lr 1e-3 \\\n",
        "  --model_name \"convnext_base\" \\\n",
        "  --num_workers 0 \\\n",
        "  --dry_run\n"
      ],
      "metadata": {
        "id": "7sOGovh9JIAh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8029311e-96a5-483d-c034-360b6559487d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/qv-pipe-classifier\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 999, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchvision/ops/__init__.py\", line 1, in <module>\n",
            "    from ._register_onnx_ops import _register_custom_op\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchvision/ops/_register_onnx_ops.py\", line 5, in <module>\n",
            "    from torch.onnx import symbolic_opset11 as opset11\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/onnx/__init__.py\", line 27, in <module>\n",
            "    from . import errors, ops\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/content/qv-pipe-classifier/src/train/super_images_baseline.py\", line 14, in <module>\n",
            "    from torchvision import transforms as T\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchvision/__init__.py\", line 10, in <module>\n",
            "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils  # usort:skip\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchvision/models/__init__.py\", line 2, in <module>\n",
            "    from .convnext import *\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py\", line 9, in <module>\n",
            "    from ..ops.misc import Conv2dNormActivation, Permute\n",
            "  File \"<frozen importlib._bootstrap>\", line 1357, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 420, in __exit__\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mini entrainement réel"
      ],
      "metadata": {
        "id": "iiKmIvYgixXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/qv-pipe-classifier\n",
        "\n",
        "!python -m src.train.super_images_baseline \\\n",
        "  --splits_csv \"{SPLITS_CSV}\" \\\n",
        "  --models_dir \"{MODELS_DIR}\" \\\n",
        "  --fold 0 \\\n",
        "  --epochs 2 \\\n",
        "  --batch_size 4 \\\n",
        "  --lr 1e-3 \\\n",
        "  --model_name \"convnext_base\" \\\n",
        "  --num_workers 4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8hbYXOCi0-Z",
        "outputId": "ed0cae9a-98e4-4231-9671-f18093976aa0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/qv-pipe-classifier\n",
            "[INFO] Using device: cuda\n",
            "[INFO] Loading splits CSV from /content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\n",
            "[INFO] Found 2881 super-images avec labels.\n",
            "[INFO] Inferred num_classes = 17\n",
            "[INFO] Fold 0: train samples = 2303, val samples = 578\n",
            "[INFO] Train batches: 576, Val batches: 145\n",
            "[INFO] Creating backbone: convnext_base\n",
            "\n",
            "Epoch 1/2\n",
            "Epoch 1: train_loss=0.2704, val_loss=0.2686, val_mAP=0.1047, lr=0.000500\n",
            "New best mAP = 0.1047 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 2/2\n",
            "Epoch 2: train_loss=0.2627, val_loss=0.2650, val_mAP=0.1049, lr=0.000000\n",
            "New best mAP = 0.1049 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Training finished.\n",
            "Best mAP on fold 0 = 0.1049\n",
            "Best model saved at: /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/best_model.pth\n",
            "History saved at:    /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/history.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrainement des 5 folds sur 20 epoch pour les superimage\n",
        "\n",
        "Une fois le dry run validé, lancer un entraînement simple sur un fold pour tester le modele."
      ],
      "metadata": {
        "id": "ZYj_MlneJKFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m src.train.super_images_baseline \\\n",
        "  --splits_csv \"{SPLITS_CSV}\" \\\n",
        "  --models_dir \"{MODELS_DIR}\" \\\n",
        "  --fold 0 \\\n",
        "  --epochs 20 \\\n",
        "  --batch_size 4 \\\n",
        "  --lr 1e-3 \\\n",
        "  --model_name \"convnext_base\" \\\n",
        "  --num_workers 12\n"
      ],
      "metadata": {
        "id": "Fdva3FFPJScK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e7577aa-5537-40e1-9ade-b0828e88920e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using device: cuda\n",
            "[INFO] Loading splits CSV from /content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\n",
            "[INFO] Found 2881 super-images avec labels.\n",
            "[INFO] Inferred num_classes = 17\n",
            "[INFO] Fold 0: train samples = 2303, val samples = 578\n",
            "[INFO] Train batches: 576, Val batches: 145\n",
            "[INFO] Creating backbone: convnext_base\n",
            "\n",
            "Epoch 1/20\n",
            "Epoch 1: train_loss=0.2704, val_loss=0.2686, val_mAP=0.1047, lr=0.000994\n",
            "New best mAP = 0.1047 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 2/20\n",
            "Epoch 2: train_loss=0.2646, val_loss=0.2655, val_mAP=0.1058, lr=0.000976\n",
            "New best mAP = 0.1058 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 3/20\n",
            "Epoch 3: train_loss=0.2631, val_loss=0.2666, val_mAP=0.0959, lr=0.000946\n",
            "\n",
            "Epoch 4/20\n",
            "Epoch 4: train_loss=0.2629, val_loss=0.2651, val_mAP=0.1001, lr=0.000905\n",
            "\n",
            "Epoch 5/20\n",
            "Epoch 5: train_loss=0.2626, val_loss=0.2634, val_mAP=0.1006, lr=0.000854\n",
            "\n",
            "Epoch 6/20\n",
            "Epoch 6: train_loss=0.2619, val_loss=0.2650, val_mAP=0.1008, lr=0.000794\n",
            "\n",
            "Epoch 7/20\n",
            "Epoch 7: train_loss=0.2621, val_loss=0.2651, val_mAP=0.1007, lr=0.000727\n",
            "\n",
            "Epoch 8/20\n",
            "Epoch 8: train_loss=0.2615, val_loss=0.2651, val_mAP=0.0991, lr=0.000655\n",
            "\n",
            "Epoch 9/20\n",
            "Epoch 9: train_loss=0.2606, val_loss=0.2624, val_mAP=0.1142, lr=0.000578\n",
            "New best mAP = 0.1142 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 10/20\n",
            "Epoch 10: train_loss=0.2590, val_loss=0.2633, val_mAP=0.1087, lr=0.000500\n",
            "\n",
            "Epoch 11/20\n",
            "Epoch 11: train_loss=0.2590, val_loss=0.2617, val_mAP=0.1047, lr=0.000422\n",
            "\n",
            "Epoch 12/20\n",
            "Epoch 12: train_loss=0.2583, val_loss=0.2625, val_mAP=0.1109, lr=0.000345\n",
            "\n",
            "Epoch 13/20\n",
            "Epoch 13: train_loss=0.2579, val_loss=0.2628, val_mAP=0.1070, lr=0.000273\n",
            "\n",
            "Epoch 14/20\n",
            "Epoch 14: train_loss=0.2573, val_loss=0.2620, val_mAP=0.1105, lr=0.000206\n",
            "\n",
            "Epoch 15/20\n",
            "Epoch 15: train_loss=0.2570, val_loss=0.2615, val_mAP=0.1108, lr=0.000146\n",
            "\n",
            "Epoch 16/20\n",
            "Epoch 16: train_loss=0.2564, val_loss=0.2620, val_mAP=0.1126, lr=0.000095\n",
            "\n",
            "Epoch 17/20\n",
            "Epoch 17: train_loss=0.2561, val_loss=0.2619, val_mAP=0.1115, lr=0.000054\n",
            "\n",
            "Epoch 18/20\n",
            "Epoch 18: train_loss=0.2559, val_loss=0.2619, val_mAP=0.1168, lr=0.000024\n",
            "New best mAP = 0.1168 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 19/20\n",
            "Epoch 19: train_loss=0.2555, val_loss=0.2616, val_mAP=0.1151, lr=0.000006\n",
            "\n",
            "Epoch 20/20\n",
            "Epoch 20: train_loss=0.2553, val_loss=0.2617, val_mAP=0.1150, lr=0.000000\n",
            "\n",
            "Training finished.\n",
            "Best mAP on fold 0 = 0.1168\n",
            "Best model saved at: /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/best_model.pth\n",
            "History saved at:    /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/history.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ConvNeXt-Base, super-images 3×3, BCE, lr=1e-3 → mAP ≈ 0.117 sur le fold 0."
      ],
      "metadata": {
        "id": "iDfBH4JxwDLV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stagne --> modele qui prend peu de risque\n",
        "\n"
      ],
      "metadata": {
        "id": "hWoPW1GLufP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/qv-pipe-classifier\n",
        "\n",
        "NEW_MODELS_DIR = \"/content/drive/MyDrive/QV Pipe/models/super_images_convnext_lr3e-3\"\n",
        "\n",
        "!python -m src.train.super_images_baseline \\\n",
        "  --splits_csv \"{SPLITS_CSV}\" \\\n",
        "  --models_dir \"{NEW_MODELS_DIR}\" \\\n",
        "  --fold 0 \\\n",
        "  --epochs 20 \\\n",
        "  --batch_size 4 \\\n",
        "  --lr 3e-3 \\\n",
        "  --model_name \"convnext_base\" \\\n",
        "  --num_workers 12\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tnguVRqEvafv",
        "outputId": "8d5e72c3-9e04-4637-db99-7cbfa29ec2a8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/qv-pipe-classifier\n",
            "[INFO] Using device: cuda\n",
            "[INFO] Loading splits CSV from /content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\n",
            "[INFO] Found 2881 super-images avec labels.\n",
            "[INFO] Inferred num_classes = 17\n",
            "[INFO] Fold 0: train samples = 2303, val samples = 578\n",
            "[INFO] Train batches: 576, Val batches: 145\n",
            "[INFO] Creating backbone: convnext_base\n",
            "\n",
            "Epoch 1/20\n",
            "Epoch 1: train_loss=0.2731, val_loss=0.2695, val_mAP=0.1017, lr=0.002982\n",
            "New best mAP = 0.1017 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_lr3e-3/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 2/20\n",
            "Epoch 2: train_loss=0.2651, val_loss=0.2666, val_mAP=0.1063, lr=0.002927\n",
            "New best mAP = 0.1063 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_lr3e-3/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 3/20\n",
            "Epoch 3: train_loss=0.2638, val_loss=0.2671, val_mAP=0.0968, lr=0.002837\n",
            "\n",
            "Epoch 4/20\n",
            "Epoch 4: train_loss=0.2632, val_loss=0.2651, val_mAP=0.0960, lr=0.002714\n",
            "\n",
            "Epoch 5/20\n",
            "Epoch 5: train_loss=0.2626, val_loss=0.2646, val_mAP=0.0975, lr=0.002561\n",
            "\n",
            "Epoch 6/20\n",
            "Epoch 6: train_loss=0.2622, val_loss=0.2647, val_mAP=0.1024, lr=0.002382\n",
            "\n",
            "Epoch 7/20\n",
            "Epoch 7: train_loss=0.2622, val_loss=0.2656, val_mAP=0.1004, lr=0.002181\n",
            "\n",
            "Epoch 8/20\n",
            "Epoch 8: train_loss=0.2619, val_loss=0.2650, val_mAP=0.1021, lr=0.001964\n",
            "\n",
            "Epoch 9/20\n",
            "Epoch 9: train_loss=0.2617, val_loss=0.2643, val_mAP=0.0920, lr=0.001735\n",
            "\n",
            "Epoch 10/20\n",
            "Epoch 10: train_loss=0.2612, val_loss=0.2645, val_mAP=0.0955, lr=0.001500\n",
            "\n",
            "Epoch 11/20\n",
            "Epoch 11: train_loss=0.2615, val_loss=0.2642, val_mAP=0.0950, lr=0.001265\n",
            "\n",
            "Epoch 12/20\n",
            "Epoch 12: train_loss=0.2610, val_loss=0.2639, val_mAP=0.0935, lr=0.001036\n",
            "\n",
            "Epoch 13/20\n",
            "Epoch 13: train_loss=0.2609, val_loss=0.2640, val_mAP=0.0993, lr=0.000819\n",
            "\n",
            "Epoch 14/20\n",
            "Epoch 14: train_loss=0.2606, val_loss=0.2637, val_mAP=0.1015, lr=0.000618\n",
            "\n",
            "Epoch 15/20\n",
            "Epoch 15: train_loss=0.2604, val_loss=0.2635, val_mAP=0.1000, lr=0.000439\n",
            "\n",
            "Epoch 16/20\n",
            "Epoch 16: train_loss=0.2603, val_loss=0.2637, val_mAP=0.1003, lr=0.000286\n",
            "\n",
            "Epoch 17/20\n",
            "Epoch 17: train_loss=0.2602, val_loss=0.2635, val_mAP=0.1008, lr=0.000163\n",
            "\n",
            "Epoch 18/20\n",
            "Epoch 18: train_loss=0.2600, val_loss=0.2635, val_mAP=0.0969, lr=0.000073\n",
            "\n",
            "Epoch 19/20\n",
            "Epoch 19: train_loss=0.2599, val_loss=0.2635, val_mAP=0.0942, lr=0.000018\n",
            "\n",
            "Epoch 20/20\n",
            "Epoch 20: train_loss=0.2598, val_loss=0.2635, val_mAP=0.0941, lr=0.000000\n",
            "\n",
            "Training finished.\n",
            "Best mAP on fold 0 = 0.1063\n",
            "Best model saved at: /content/drive/MyDrive/QV Pipe/models/super_images_convnext_lr3e-3/convnext_base_fold0/best_model.pth\n",
            "History saved at:    /content/drive/MyDrive/QV Pipe/models/super_images_convnext_lr3e-3/convnext_base_fold0/history.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fonction de perte : passage de BCE à ASL\n",
        "\n",
        "Initialement, la baseline utilisait une perte BCEWithLogitsLoss classique, bien adaptée à la classification multi-label mais peu robuste au fort déséquilibre de classes du dataset QV Pipe (beaucoup de zéros, peu de positives par classe)."
      ],
      "metadata": {
        "id": "GCsklQnZ-gIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SPLITS_CSV = \"/content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\"\n",
        "\n",
        "# Nouveau dossier pour cette expérience (ASL + flip)\n",
        "MODELS_DIR = \"/content/drive/MyDrive/QV Pipe/models/super_images_convnext_ASL\""
      ],
      "metadata": {
        "id": "feifYCjQAqEV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m src.train.super_images_baseline \\\n",
        "  --splits_csv \"{SPLITS_CSV}\" \\\n",
        "  --models_dir \"{MODELS_DIR}\" \\\n",
        "  --fold 0 \\\n",
        "  --epochs 20 \\\n",
        "  --batch_size 4 \\\n",
        "  --lr 1e-3 \\\n",
        "  --model_name \"convnext_base\" \\\n",
        "  --num_workers 12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Al3QHVwQBDcn",
        "outputId": "af6a814d-b957-403e-dfd3-895dbd3bf88a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using device: cuda\n",
            "[INFO] Loading splits CSV from /content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\n",
            "[INFO] Found 2881 super-images avec labels.\n",
            "[INFO] Inferred num_classes = 17\n",
            "[INFO] Fold 0: train samples = 2303, val samples = 578\n",
            "[INFO] Train batches: 576, Val batches: 145\n",
            "[INFO] Creating backbone: convnext_base\n",
            "model.safetensors: 100% 354M/354M [00:01<00:00, 291MB/s]\n",
            "\n",
            "Epoch 1/20\n",
            "Epoch 1: train_loss=0.0766, val_loss=0.0753, val_mAP=0.1205, lr=0.000994\n",
            "New best mAP = 0.1205 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_ASL/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 2/20\n",
            "Epoch 2: train_loss=0.0749, val_loss=0.0749, val_mAP=0.1114, lr=0.000976\n",
            "\n",
            "Epoch 3/20\n",
            "Epoch 3: train_loss=0.0744, val_loss=0.0753, val_mAP=0.1131, lr=0.000946\n",
            "\n",
            "Epoch 4/20\n",
            "Epoch 4: train_loss=0.0743, val_loss=0.0751, val_mAP=0.1029, lr=0.000905\n",
            "\n",
            "Epoch 5/20\n",
            "Epoch 5: train_loss=0.0744, val_loss=0.0749, val_mAP=0.1030, lr=0.000854\n",
            "\n",
            "Epoch 6/20\n",
            "Epoch 6: train_loss=0.0742, val_loss=0.0747, val_mAP=0.1095, lr=0.000794\n",
            "\n",
            "Epoch 7/20\n",
            "Epoch 7: train_loss=0.0741, val_loss=0.0747, val_mAP=0.1115, lr=0.000727\n",
            "\n",
            "Epoch 8/20\n",
            "Epoch 8: train_loss=0.0739, val_loss=0.0746, val_mAP=0.1124, lr=0.000655\n",
            "\n",
            "Epoch 9/20\n",
            "Epoch 9: train_loss=0.0738, val_loss=0.0745, val_mAP=0.1098, lr=0.000578\n",
            "\n",
            "Epoch 10/20\n",
            "Epoch 10: train_loss=0.0736, val_loss=0.0745, val_mAP=0.1157, lr=0.000500\n",
            "\n",
            "Epoch 11/20\n",
            "Epoch 11: train_loss=0.0743, val_loss=0.0745, val_mAP=0.1068, lr=0.000422\n",
            "\n",
            "Epoch 12/20\n",
            "Epoch 12: train_loss=0.0735, val_loss=0.0739, val_mAP=0.1179, lr=0.000345\n",
            "\n",
            "Epoch 13/20\n",
            "Epoch 13: train_loss=0.0729, val_loss=0.0736, val_mAP=0.1291, lr=0.000273\n",
            "New best mAP = 0.1291 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_ASL/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 14/20\n",
            "Epoch 14: train_loss=0.0725, val_loss=0.0733, val_mAP=0.1304, lr=0.000206\n",
            "New best mAP = 0.1304 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_ASL/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 15/20\n",
            "Epoch 15: train_loss=0.0721, val_loss=0.0730, val_mAP=0.1389, lr=0.000146\n",
            "New best mAP = 0.1389 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_ASL/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 16/20\n",
            "Epoch 16: train_loss=0.0718, val_loss=0.0731, val_mAP=0.1383, lr=0.000095\n",
            "\n",
            "Epoch 17/20\n",
            "Epoch 17: train_loss=0.0714, val_loss=0.0726, val_mAP=0.1446, lr=0.000054\n",
            "New best mAP = 0.1446 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_ASL/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 18/20\n",
            "Epoch 18: train_loss=0.0710, val_loss=0.0725, val_mAP=0.1455, lr=0.000024\n",
            "New best mAP = 0.1455 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_ASL/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 19/20\n",
            "Epoch 19: train_loss=0.0707, val_loss=0.0724, val_mAP=0.1489, lr=0.000006\n",
            "New best mAP = 0.1489 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_ASL/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 20/20\n",
            "Epoch 20: train_loss=0.0706, val_loss=0.0725, val_mAP=0.1489, lr=0.000000\n",
            "\n",
            "Training finished.\n",
            "Best mAP on fold 0 = 0.1489\n",
            "Best model saved at: /content/drive/MyDrive/QV Pipe/models/super_images_convnext_ASL/convnext_base_fold0/best_model.pth\n",
            "History saved at:    /content/drive/MyDrive/QV Pipe/models/super_images_convnext_ASL/convnext_base_fold0/history.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sanity check"
      ],
      "metadata": {
        "id": "B6meOzHIKTxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "full_df = pd.read_csv(SPLITS_CSV)\n",
        "\n",
        "# On prend uniquement des samples de train pour fold 0 (par ex.)\n",
        "mini_df = full_df[full_df[\"fold\"] != 0].sample(n=32, random_state=42)\n",
        "\n",
        "mini_csv_path = \"/content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_mini_overfit.csv\"\n",
        "mini_df.to_csv(mini_csv_path, index=False)\n",
        "\n",
        "mini_df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "DZXA0qhpKR59",
        "outputId": "680f9070-85c4-490a-af28-c403f4307c0c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     video_stem                                    superimage_path labels_str  \\\n",
              "1172     d16428  /content/drive/MyDrive/QV Pipe/data/super_imag...          3   \n",
              "1614     d20926  /content/drive/MyDrive/QV Pipe/data/super_imag...          9   \n",
              "1635     d21125  /content/drive/MyDrive/QV Pipe/data/super_imag...        1 7   \n",
              "1579     d20846  /content/drive/MyDrive/QV Pipe/data/super_imag...       1 10   \n",
              "590         460  /content/drive/MyDrive/QV Pipe/data/super_imag...          0   \n",
              "\n",
              "      fold  \n",
              "1172     1  \n",
              "1614     3  \n",
              "1635     4  \n",
              "1579     3  \n",
              "590      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46712199-e97a-4804-a492-8a9de3d65437\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_stem</th>\n",
              "      <th>superimage_path</th>\n",
              "      <th>labels_str</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1172</th>\n",
              "      <td>d16428</td>\n",
              "      <td>/content/drive/MyDrive/QV Pipe/data/super_imag...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1614</th>\n",
              "      <td>d20926</td>\n",
              "      <td>/content/drive/MyDrive/QV Pipe/data/super_imag...</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1635</th>\n",
              "      <td>d21125</td>\n",
              "      <td>/content/drive/MyDrive/QV Pipe/data/super_imag...</td>\n",
              "      <td>1 7</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1579</th>\n",
              "      <td>d20846</td>\n",
              "      <td>/content/drive/MyDrive/QV Pipe/data/super_imag...</td>\n",
              "      <td>1 10</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>590</th>\n",
              "      <td>460</td>\n",
              "      <td>/content/drive/MyDrive/QV Pipe/data/super_imag...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46712199-e97a-4804-a492-8a9de3d65437')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-46712199-e97a-4804-a492-8a9de3d65437 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-46712199-e97a-4804-a492-8a9de3d65437');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2cda841a-2ea4-4274-8995-bd9aea92a0c6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2cda841a-2ea4-4274-8995-bd9aea92a0c6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2cda841a-2ea4-4274-8995-bd9aea92a0c6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "mini_df",
              "summary": "{\n  \"name\": \"mini_df\",\n  \"rows\": 32,\n  \"fields\": [\n    {\n      \"column\": \"video_stem\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 32,\n        \"samples\": [\n          \"25162\",\n          \"3654\",\n          \"d7298\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"superimage_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 32,\n        \"samples\": [\n          \"/content/drive/MyDrive/QV Pipe/data/super_images_3x3/25162_3x3.jpg\",\n          \"/content/drive/MyDrive/QV Pipe/data/super_images_3x3/3654_3x3.jpg\",\n          \"/content/drive/MyDrive/QV Pipe/data/super_images_3x3/d7298_3x3.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels_str\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 23,\n        \"samples\": [\n          \"2 4 13\",\n          \"3 6 8 15\",\n          \"3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fold\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3,\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from src.train.super_images_baseline import parse_labels_str\n",
        "\n",
        "df = pd.read_csv(SPLITS_CSV)\n",
        "\n",
        "# Convertit labels_str en listes d'indices\n",
        "labels_lists = df[\"labels_str\"].apply(parse_labels_str).tolist()\n",
        "\n",
        "# Nombre de classes inféré comme dans le script\n",
        "all_labels = []\n",
        "for lst in labels_lists:\n",
        "    all_labels.extend(lst)\n",
        "num_classes = max(all_labels) + 1\n",
        "print(\"num_classes =\", num_classes)\n",
        "\n",
        "# Comptage du nombre de vidéos positives par classe\n",
        "counts = np.zeros(num_classes, dtype=int)\n",
        "for lst in labels_lists:\n",
        "    for c in lst:\n",
        "        if 0 <= c < num_classes:\n",
        "            counts[c] += 1\n",
        "\n",
        "for cls_idx, n in enumerate(counts):\n",
        "    print(f\"Classe {cls_idx:2d} : {n} vidéos positives\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faoA0H-oK5Pf",
        "outputId": "b5b9adb5-92bd-4e40-d2f0-3d94ce5d97bd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_classes = 17\n",
            "Classe  0 : 538 vidéos positives\n",
            "Classe  1 : 791 vidéos positives\n",
            "Classe  2 : 509 vidéos positives\n",
            "Classe  3 : 420 vidéos positives\n",
            "Classe  4 : 388 vidéos positives\n",
            "Classe  5 : 169 vidéos positives\n",
            "Classe  6 : 243 vidéos positives\n",
            "Classe  7 : 220 vidéos positives\n",
            "Classe  8 : 172 vidéos positives\n",
            "Classe  9 : 131 vidéos positives\n",
            "Classe 10 : 204 vidéos positives\n",
            "Classe 11 : 100 vidéos positives\n",
            "Classe 12 : 79 vidéos positives\n",
            "Classe 13 : 37 vidéos positives\n",
            "Classe 14 : 40 vidéos positives\n",
            "Classe 15 : 102 vidéos positives\n",
            "Classe 16 : 33 vidéos positives\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xowCCF82Fs7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from src.train.super_images_baseline import parse_labels_str  # même fonction que framewise\n",
        "\n",
        "SPLITS_CSV = \"/content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\"\n",
        "df = pd.read_csv(SPLITS_CSV)\n",
        "\n",
        "labels_lists = df[\"labels_str\"].apply(parse_labels_str).tolist()\n",
        "\n",
        "all_labels = []\n",
        "for lst in labels_lists:\n",
        "    all_labels.extend(lst)\n",
        "\n",
        "num_classes = max(all_labels) + 1 if len(all_labels) > 0 else 0\n",
        "print(\"num_classes =\", num_classes)\n",
        "\n",
        "counts = np.zeros(num_classes, dtype=int)\n",
        "for lst in labels_lists:\n",
        "    for c in lst:\n",
        "        if 0 <= c < num_classes:\n",
        "            counts[c] += 1\n",
        "\n",
        "for cls_idx, n in enumerate(counts):\n",
        "    print(f\"Classe {cls_idx:2d} : {n} super-images positives\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9ZahzmjNGGC",
        "outputId": "5b13443e-a1ed-4d83-e24f-98902aa35e5a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_classes = 17\n",
            "Classe  0 : 538 super-images positives\n",
            "Classe  1 : 791 super-images positives\n",
            "Classe  2 : 509 super-images positives\n",
            "Classe  3 : 420 super-images positives\n",
            "Classe  4 : 388 super-images positives\n",
            "Classe  5 : 169 super-images positives\n",
            "Classe  6 : 243 super-images positives\n",
            "Classe  7 : 220 super-images positives\n",
            "Classe  8 : 172 super-images positives\n",
            "Classe  9 : 131 super-images positives\n",
            "Classe 10 : 204 super-images positives\n",
            "Classe 11 : 100 super-images positives\n",
            "Classe 12 : 79 super-images positives\n",
            "Classe 13 : 37 super-images positives\n",
            "Classe 14 : 40 super-images positives\n",
            "Classe 15 : 102 super-images positives\n",
            "Classe 16 : 33 super-images positives\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_empty = sum(len(lst) == 0 for lst in labels_lists)\n",
        "print(\"Super-images sans aucun label :\", num_empty, \"/\", len(labels_lists))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xy5NnB5-NGlm",
        "outputId": "51ced89f-c120-40b7-997f-1090b7a0e29c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Super-images sans aucun label : 0 / 2881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion : nos labels sont OK"
      ],
      "metadata": {
        "id": "c8sork9DTBrD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Juste améliorer la “qualité image”\n",
        "\n",
        "Objectif : voir si augmenter la résolution suffit déjà à faire monter la mAP."
      ],
      "metadata": {
        "id": "1blH_ceLTD7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m src.train.super_images_baseline \\\n",
        "  --csv_path \"/content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\" \\\n",
        "  --models_dir \"/content/drive/MyDrive/QV Pipe/models/super_images_convnext\" \\\n",
        "  --fold 0 \\\n",
        "  --epochs 20 \\\n",
        "  --batch_size 4 \\\n",
        "  --lr 1e-3 \\\n",
        "  --model_name \"convnext_base\" \\\n",
        "  --img_size 1344 \\\n",
        "  --num_workers 8\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hL6RuJuHNOt9",
        "outputId": "f31ce60a-9786-4e6c-c027-dd4bd6f03b60"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading CSV from /content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\n",
            "Inferred num_classes = 17\n",
            "Fold 0 -> train samples: 2303, val samples: 578\n",
            "Train batches: 576, Val batches: 145\n",
            "Creating model: convnext_base\n",
            "\n",
            "Epoch 1/20\n",
            "Train loss: 0.2205\n",
            "Val loss  : 0.1871\n",
            "Val mAP   : 0.4420\n",
            "LR        : 0.000104\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/best_model.pth (mAP=0.4420)\n",
            "\n",
            "Epoch 2/20\n",
            "Train loss: 0.1785\n",
            "Val loss  : 0.2063\n",
            "Val mAP   : 0.4373\n",
            "LR        : 0.000280\n",
            "\n",
            "Epoch 3/20\n",
            "Train loss: 0.1740\n",
            "Val loss  : 0.1986\n",
            "Val mAP   : 0.4314\n",
            "LR        : 0.000520\n",
            "\n",
            "Epoch 4/20\n",
            "Train loss: 0.1766\n",
            "Val loss  : 0.1963\n",
            "Val mAP   : 0.4578\n",
            "LR        : 0.000760\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/best_model.pth (mAP=0.4578)\n",
            "\n",
            "Epoch 5/20\n",
            "Train loss: 0.1809\n",
            "Val loss  : 0.1882\n",
            "Val mAP   : 0.4674\n",
            "LR        : 0.000936\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/best_model.pth (mAP=0.4674)\n",
            "\n",
            "Epoch 6/20\n",
            "Train loss: 0.1784\n",
            "Val loss  : 0.2240\n",
            "Val mAP   : 0.4098\n",
            "LR        : 0.001000\n",
            "\n",
            "Epoch 7/20\n",
            "Train loss: 0.1663\n",
            "Val loss  : 0.2047\n",
            "Val mAP   : 0.3992\n",
            "LR        : 0.000987\n",
            "\n",
            "Epoch 8/20\n",
            "Train loss: 0.1588\n",
            "Val loss  : 0.2210\n",
            "Val mAP   : 0.4159\n",
            "LR        : 0.000950\n",
            "\n",
            "Epoch 9/20\n",
            "Train loss: 0.1444\n",
            "Val loss  : 0.1848\n",
            "Val mAP   : 0.4913\n",
            "LR        : 0.000891\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/best_model.pth (mAP=0.4913)\n",
            "\n",
            "Epoch 10/20\n",
            "Train loss: 0.1269\n",
            "Val loss  : 0.2006\n",
            "Val mAP   : 0.4549\n",
            "LR        : 0.000812\n",
            "\n",
            "Epoch 11/20\n",
            "Train loss: 0.1074\n",
            "Val loss  : 0.2002\n",
            "Val mAP   : 0.4546\n",
            "LR        : 0.000717\n",
            "\n",
            "Epoch 12/20\n",
            "Train loss: 0.0859\n",
            "Val loss  : 0.2313\n",
            "Val mAP   : 0.4657\n",
            "LR        : 0.000611\n",
            "\n",
            "Epoch 13/20\n",
            "Train loss: 0.0589\n",
            "Val loss  : 0.2773\n",
            "Val mAP   : 0.4767\n",
            "LR        : 0.000500\n",
            "\n",
            "Epoch 14/20\n",
            "Train loss: 0.0401\n",
            "Val loss  : 0.2756\n",
            "Val mAP   : 0.4831\n",
            "LR        : 0.000389\n",
            "\n",
            "Epoch 15/20\n",
            "Train loss: 0.0205\n",
            "Val loss  : 0.3269\n",
            "Val mAP   : 0.4789\n",
            "LR        : 0.000283\n",
            "\n",
            "Epoch 16/20\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/content/qv-pipe-classifier/src/train/super_images_baseline.py\", line 498, in <module>\n",
            "    main()\n",
            "  File \"/content/qv-pipe-classifier/src/train/super_images_baseline.py\", line 442, in main\n",
            "    train_loss = train_one_epoch(\n",
            "                 ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/qv-pipe-classifier/src/train/super_images_baseline.py\", line 245, in train_one_epoch\n",
            "    running_loss += loss.item() * batch_size\n",
            "                    ^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CCL --> la qualité d'image y est pour beaucoup !!"
      ],
      "metadata": {
        "id": "3_QeML0aEdv7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour rendre le code un peu moins agressif on passe lr de 1e-3 a 5e-4\n",
        "\n",
        "Loss : BCE"
      ],
      "metadata": {
        "id": "BhSZPwBkFFfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m src.train.super_images_baseline \\\n",
        "  --csv_path \"/content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\" \\\n",
        "  --models_dir \"/content/drive/MyDrive/QV Pipe/models/super_images_convnext\" \\\n",
        "  --fold 1 \\\n",
        "  --epochs 15 \\\n",
        "  --batch_size 4 \\\n",
        "  --lr 5e-4 \\\n",
        "  --model_name \"convnext_base\" \\\n",
        "  --img_size 1344 \\\n",
        "  --num_workers 12\n"
      ],
      "metadata": {
        "id": "vbynr6mSVuEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## training avec bonne qualité d'image et remplacer BCE par CB Focal"
      ],
      "metadata": {
        "id": "s5ZTN-VoEhcY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m src.train.super_images_baseline_CBfocal \\\n",
        "  --csv_path \"/content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\" \\\n",
        "  --models_dir \"/content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal\" \\\n",
        "  --fold 0 \\\n",
        "  --epochs 15 \\\n",
        "  --batch_size 4 \\\n",
        "  --lr 5e-4 \\\n",
        "  --model_name \"convnext_base\" \\\n",
        "  --img_size 1344 \\\n",
        "  --num_workers 12\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSlNw7MiFi1_",
        "outputId": "b582e20e-f469-48a1-a9c1-e06b1a1a2047"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using device: cuda\n",
            "[INFO] Loading CSV from /content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\n",
            "[INFO] Inferred num_classes = 17\n",
            "[INFO] Fold 0: train samples = 2303, val samples = 578\n",
            "[INFO] Class counts (train) : [433, 637, 415, 338, 304, 134, 189, 171, 135, 102, 163, 81, 63, 27, 30, 89, 25]\n",
            "[INFO] Train batches: 576, Val batches: 145\n",
            "[INFO] Creating backbone: convnext_base\n",
            "[INFO] Using Class-Balanced Focal Loss\n",
            "\n",
            "Epoch 1/15\n",
            "Train loss: 0.0399\n",
            "Val loss  : 0.0375\n",
            "Val mAP   : 0.3649\n",
            "LR        : 0.000076\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold0/best_model.pth (mAP=0.3649)\n",
            "\n",
            "Epoch 2/15\n",
            "Train loss: 0.0330\n",
            "Val loss  : 0.0351\n",
            "Val mAP   : 0.4499\n",
            "LR        : 0.000218\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold0/best_model.pth (mAP=0.4499)\n",
            "\n",
            "Epoch 3/15\n",
            "Train loss: 0.0311\n",
            "Val loss  : 0.0334\n",
            "Val mAP   : 0.4133\n",
            "LR        : 0.000380\n",
            "\n",
            "Epoch 4/15\n",
            "Train loss: 0.0307\n",
            "Val loss  : 0.0409\n",
            "Val mAP   : 0.4340\n",
            "LR        : 0.000486\n",
            "\n",
            "Epoch 5/15\n",
            "Train loss: 0.0281\n",
            "Val loss  : 0.0332\n",
            "Val mAP   : 0.4665\n",
            "LR        : 0.000497\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold0/best_model.pth (mAP=0.4665)\n",
            "\n",
            "Epoch 6/15\n",
            "Train loss: 0.0280\n",
            "Val loss  : 0.0362\n",
            "Val mAP   : 0.4313\n",
            "LR        : 0.000475\n",
            "\n",
            "Epoch 7/15\n",
            "Train loss: 0.0245\n",
            "Val loss  : 0.0355\n",
            "Val mAP   : 0.4726\n",
            "LR        : 0.000433\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold0/best_model.pth (mAP=0.4726)\n",
            "\n",
            "Epoch 8/15\n",
            "Train loss: 0.0183\n",
            "Val loss  : 0.0391\n",
            "Val mAP   : 0.4706\n",
            "LR        : 0.000375\n",
            "\n",
            "Epoch 9/15\n",
            "Train loss: 0.0154\n",
            "Val loss  : 0.0406\n",
            "Val mAP   : 0.4889\n",
            "LR        : 0.000306\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold0/best_model.pth (mAP=0.4889)\n",
            "\n",
            "Epoch 10/15\n",
            "Train loss: 0.0110\n",
            "Val loss  : 0.0440\n",
            "Val mAP   : 0.5090\n",
            "LR        : 0.000231\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold0/best_model.pth (mAP=0.5090)\n",
            "\n",
            "Epoch 11/15\n",
            "Train loss: 0.0057\n",
            "Val loss  : 0.0530\n",
            "Val mAP   : 0.5071\n",
            "LR        : 0.000159\n",
            "\n",
            "Epoch 12/15\n",
            "Train loss: 0.0030\n",
            "Val loss  : 0.0694\n",
            "Val mAP   : 0.5156\n",
            "LR        : 0.000094\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold0/best_model.pth (mAP=0.5156)\n",
            "\n",
            "Epoch 13/15\n",
            "Train loss: 0.0014\n",
            "Val loss  : 0.0974\n",
            "Val mAP   : 0.5119\n",
            "LR        : 0.000043\n",
            "\n",
            "Epoch 14/15\n",
            "Train loss: 0.0005\n",
            "Val loss  : 0.1162\n",
            "Val mAP   : 0.5074\n",
            "LR        : 0.000011\n",
            "\n",
            "Epoch 15/15\n",
            "Train loss: 0.0003\n",
            "Val loss  : 0.1175\n",
            "Val mAP   : 0.5066\n",
            "LR        : 0.000000\n",
            "\n",
            "Training finished.\n",
            "Best val mAP on fold 0: 0.5156\n",
            "Best model path: /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold0/best_model.pth\n",
            "History saved to: /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold0/history.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m src.train.super_images_baseline_CBfocal \\\n",
        "  --csv_path \"/content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\" \\\n",
        "  --models_dir \"/content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal\" \\\n",
        "  --fold 1 \\\n",
        "  --epochs 15 \\\n",
        "  --batch_size 4 \\\n",
        "  --lr 5e-4 \\\n",
        "  --model_name \"convnext_base\" \\\n",
        "  --img_size 1344 \\\n",
        "  --num_workers 12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWuepYwQF56w",
        "outputId": "1effaa6e-8544-4197-f4f8-356b44633707"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using device: cuda\n",
            "[INFO] Loading CSV from /content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\n",
            "[INFO] Inferred num_classes = 17\n",
            "[INFO] Fold 1: train samples = 2274, val samples = 607\n",
            "[INFO] Class counts (train) : [434, 619, 394, 333, 303, 128, 190, 179, 142, 107, 161, 73, 64, 30, 34, 77, 27]\n",
            "[INFO] Train batches: 569, Val batches: 152\n",
            "[INFO] Creating backbone: convnext_base\n",
            "[INFO] Using Class-Balanced Focal Loss\n",
            "\n",
            "Epoch 1/15\n",
            "Train loss: 0.0413\n",
            "Val loss  : 0.0325\n",
            "Val mAP   : 0.4205\n",
            "LR        : 0.000076\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold1/best_model.pth (mAP=0.4205)\n",
            "\n",
            "Epoch 2/15\n",
            "Train loss: 0.0351\n",
            "Val loss  : 0.0340\n",
            "Val mAP   : 0.4908\n",
            "LR        : 0.000218\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold1/best_model.pth (mAP=0.4908)\n",
            "\n",
            "Epoch 3/15\n",
            "Train loss: 0.0323\n",
            "Val loss  : 0.0311\n",
            "Val mAP   : 0.4547\n",
            "LR        : 0.000380\n",
            "\n",
            "Epoch 4/15\n",
            "Train loss: 0.0315\n",
            "Val loss  : 0.0283\n",
            "Val mAP   : 0.5010\n",
            "LR        : 0.000486\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold1/best_model.pth (mAP=0.5010)\n",
            "\n",
            "Epoch 5/15\n",
            "Train loss: 0.0290\n",
            "Val loss  : 0.0313\n",
            "Val mAP   : 0.5013\n",
            "LR        : 0.000497\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold1/best_model.pth (mAP=0.5013)\n",
            "\n",
            "Epoch 6/15\n",
            "Train loss: 0.0265\n",
            "Val loss  : 0.0324\n",
            "Val mAP   : 0.5163\n",
            "LR        : 0.000475\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold1/best_model.pth (mAP=0.5163)\n",
            "\n",
            "Epoch 7/15\n",
            "Train loss: 0.0236\n",
            "Val loss  : 0.0288\n",
            "Val mAP   : 0.4816\n",
            "LR        : 0.000433\n",
            "\n",
            "Epoch 8/15\n",
            "Train loss: 0.0185\n",
            "Val loss  : 0.0338\n",
            "Val mAP   : 0.5107\n",
            "LR        : 0.000375\n",
            "\n",
            "Epoch 9/15\n",
            "Train loss: 0.0135\n",
            "Val loss  : 0.0336\n",
            "Val mAP   : 0.5628\n",
            "LR        : 0.000306\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold1/best_model.pth (mAP=0.5628)\n",
            "\n",
            "Epoch 10/15\n",
            "Train loss: 0.0099\n",
            "Val loss  : 0.0357\n",
            "Val mAP   : 0.5493\n",
            "LR        : 0.000231\n",
            "\n",
            "Epoch 11/15\n",
            "Train loss: 0.0047\n",
            "Val loss  : 0.0430\n",
            "Val mAP   : 0.5762\n",
            "LR        : 0.000159\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold1/best_model.pth (mAP=0.5762)\n",
            "\n",
            "Epoch 12/15\n",
            "Train loss: 0.0022\n",
            "Val loss  : 0.0604\n",
            "Val mAP   : 0.5907\n",
            "LR        : 0.000094\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold1/best_model.pth (mAP=0.5907)\n",
            "\n",
            "Epoch 13/15\n",
            "Train loss: 0.0009\n",
            "Val loss  : 0.0753\n",
            "Val mAP   : 0.5989\n",
            "LR        : 0.000043\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold1/best_model.pth (mAP=0.5989)\n",
            "\n",
            "Epoch 14/15\n",
            "Train loss: 0.0003\n",
            "Val loss  : 0.0837\n",
            "Val mAP   : 0.5940\n",
            "LR        : 0.000011\n",
            "\n",
            "Epoch 15/15\n",
            "Train loss: 0.0002\n",
            "Val loss  : 0.0846\n",
            "Val mAP   : 0.5948\n",
            "LR        : 0.000000\n",
            "\n",
            "Training finished.\n",
            "Best val mAP on fold 1: 0.5989\n",
            "Best model path: /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold1/best_model.pth\n",
            "History saved to: /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold1/history.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m src.train.super_images_baseline_CBfocal \\\n",
        "  --csv_path \"/content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\" \\\n",
        "  --models_dir \"/content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal\" \\\n",
        "  --fold 2 \\\n",
        "  --epochs 15 \\\n",
        "  --batch_size 4 \\\n",
        "  --lr 5e-4 \\\n",
        "  --model_name \"convnext_base\" \\\n",
        "  --img_size 1344 \\\n",
        "  --num_workers 12"
      ],
      "metadata": {
        "id": "T_TNslpKvtxf",
        "outputId": "75a565f7-3bfc-4c08-f792-374c776b8d39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using device: cuda\n",
            "[INFO] Loading CSV from /content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\n",
            "[INFO] Inferred num_classes = 17\n",
            "[INFO] Fold 2: train samples = 2324, val samples = 557\n",
            "[INFO] Class counts (train) : [427, 637, 412, 329, 317, 139, 198, 170, 130, 104, 160, 84, 62, 30, 34, 80, 28]\n",
            "[INFO] Train batches: 581, Val batches: 140\n",
            "[INFO] Creating backbone: convnext_base\n",
            "[INFO] Using Class-Balanced Focal Loss\n",
            "\n",
            "Epoch 1/15\n",
            "Train loss: 0.0410\n",
            "Val loss  : 0.0370\n",
            "Val mAP   : 0.4017\n",
            "LR        : 0.000076\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold2/best_model.pth (mAP=0.4017)\n",
            "\n",
            "Epoch 2/15\n",
            "Train loss: 0.0342\n",
            "Val loss  : 0.0332\n",
            "Val mAP   : 0.4709\n",
            "LR        : 0.000218\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold2/best_model.pth (mAP=0.4709)\n",
            "\n",
            "Epoch 3/15\n",
            "Train loss: 0.0318\n",
            "Val loss  : 0.0300\n",
            "Val mAP   : 0.5276\n",
            "LR        : 0.000380\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold2/best_model.pth (mAP=0.5276)\n",
            "\n",
            "Epoch 4/15\n",
            "Train loss: 0.0303\n",
            "Val loss  : 0.0303\n",
            "Val mAP   : 0.5193\n",
            "LR        : 0.000486\n",
            "\n",
            "Epoch 5/15\n",
            "Train loss: 0.0287\n",
            "Val loss  : 0.0354\n",
            "Val mAP   : 0.4865\n",
            "LR        : 0.000497\n",
            "\n",
            "Epoch 6/15\n",
            "Train loss: 0.0265\n",
            "Val loss  : 0.0319\n",
            "Val mAP   : 0.5182\n",
            "LR        : 0.000475\n",
            "\n",
            "Epoch 7/15\n",
            "Train loss: 0.0228\n",
            "Val loss  : 0.0292\n",
            "Val mAP   : 0.5462\n",
            "LR        : 0.000433\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold2/best_model.pth (mAP=0.5462)\n",
            "\n",
            "Epoch 8/15\n",
            "Train loss: 0.0181\n",
            "Val loss  : 0.0296\n",
            "Val mAP   : 0.5460\n",
            "LR        : 0.000375\n",
            "\n",
            "Epoch 9/15\n",
            "Train loss: 0.0140\n",
            "Val loss  : 0.0295\n",
            "Val mAP   : 0.5573\n",
            "LR        : 0.000306\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold2/best_model.pth (mAP=0.5573)\n",
            "\n",
            "Epoch 10/15\n",
            "Train loss: 0.0092\n",
            "Val loss  : 0.0353\n",
            "Val mAP   : 0.5859\n",
            "LR        : 0.000231\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold2/best_model.pth (mAP=0.5859)\n",
            "\n",
            "Epoch 11/15\n",
            "Train loss: 0.0059\n",
            "Val loss  : 0.0466\n",
            "Val mAP   : 0.5896\n",
            "LR        : 0.000159\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold2/best_model.pth (mAP=0.5896)\n",
            "\n",
            "Epoch 12/15\n",
            "Train loss: 0.0023\n",
            "Val loss  : 0.0582\n",
            "Val mAP   : 0.6102\n",
            "LR        : 0.000094\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold2/best_model.pth (mAP=0.6102)\n",
            "\n",
            "Epoch 13/15\n",
            "Train loss: 0.0010\n",
            "Val loss  : 0.0722\n",
            "Val mAP   : 0.6097\n",
            "LR        : 0.000043\n",
            "\n",
            "Epoch 14/15\n",
            "Train loss: 0.0004\n",
            "Val loss  : 0.0840\n",
            "Val mAP   : 0.6122\n",
            "LR        : 0.000011\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold2/best_model.pth (mAP=0.6122)\n",
            "\n",
            "Epoch 15/15\n",
            "Train loss: 0.0002\n",
            "Val loss  : 0.0869\n",
            "Val mAP   : 0.6122\n",
            "LR        : 0.000000\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold2/best_model.pth (mAP=0.6122)\n",
            "\n",
            "Training finished.\n",
            "Best val mAP on fold 2: 0.6122\n",
            "Best model path: /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold2/best_model.pth\n",
            "History saved to: /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold2/history.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m src.train.super_images_baseline_CBfocal \\\n",
        "  --csv_path \"/content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\" \\\n",
        "  --models_dir \"/content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal\" \\\n",
        "  --fold 3 \\\n",
        "  --epochs 15 \\\n",
        "  --batch_size 4 \\\n",
        "  --lr 5e-4 \\\n",
        "  --model_name \"convnext_base\" \\\n",
        "  --img_size 1344 \\\n",
        "  --num_workers 12"
      ],
      "metadata": {
        "id": "X6T8_88Ovwkd",
        "outputId": "f88db006-cd41-47e7-e3ab-45f12d77e3a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using device: cuda\n",
            "[INFO] Loading CSV from /content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\n",
            "[INFO] Inferred num_classes = 17\n",
            "[INFO] Fold 3: train samples = 2301, val samples = 580\n",
            "[INFO] Class counts (train) : [433, 630, 405, 337, 312, 136, 196, 176, 137, 106, 161, 79, 67, 28, 31, 81, 27]\n",
            "[INFO] Train batches: 576, Val batches: 145\n",
            "[INFO] Creating backbone: convnext_base\n",
            "[INFO] Using Class-Balanced Focal Loss\n",
            "\n",
            "Epoch 1/15\n",
            "Train loss: 0.0405\n",
            "Val loss  : 0.0378\n",
            "Val mAP   : 0.3752\n",
            "LR        : 0.000076\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold3/best_model.pth (mAP=0.3752)\n",
            "\n",
            "Epoch 2/15\n",
            "Train loss: 0.0334\n",
            "Val loss  : 0.0339\n",
            "Val mAP   : 0.4440\n",
            "LR        : 0.000218\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold3/best_model.pth (mAP=0.4440)\n",
            "\n",
            "Epoch 3/15\n",
            "Train loss: 0.0309\n",
            "Val loss  : 0.0353\n",
            "Val mAP   : 0.4469\n",
            "LR        : 0.000380\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold3/best_model.pth (mAP=0.4469)\n",
            "\n",
            "Epoch 4/15\n",
            "Train loss: 0.0306\n",
            "Val loss  : 0.0479\n",
            "Val mAP   : 0.4051\n",
            "LR        : 0.000486\n",
            "\n",
            "Epoch 5/15\n",
            "Train loss: 0.0283\n",
            "Val loss  : 0.0319\n",
            "Val mAP   : 0.4714\n",
            "LR        : 0.000497\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold3/best_model.pth (mAP=0.4714)\n",
            "\n",
            "Epoch 6/15\n",
            "Train loss: 0.0263\n",
            "Val loss  : 0.0275\n",
            "Val mAP   : 0.5065\n",
            "LR        : 0.000475\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold3/best_model.pth (mAP=0.5065)\n",
            "\n",
            "Epoch 7/15\n",
            "Train loss: 0.0230\n",
            "Val loss  : 0.0277\n",
            "Val mAP   : 0.5200\n",
            "LR        : 0.000433\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold3/best_model.pth (mAP=0.5200)\n",
            "\n",
            "Epoch 8/15\n",
            "Train loss: 0.0205\n",
            "Val loss  : 0.0290\n",
            "Val mAP   : 0.5197\n",
            "LR        : 0.000375\n",
            "\n",
            "Epoch 9/15\n",
            "Train loss: 0.0152\n",
            "Val loss  : 0.0323\n",
            "Val mAP   : 0.5348\n",
            "LR        : 0.000306\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold3/best_model.pth (mAP=0.5348)\n",
            "\n",
            "Epoch 10/15\n",
            "Train loss: 0.0094\n",
            "Val loss  : 0.0323\n",
            "Val mAP   : 0.5740\n",
            "LR        : 0.000231\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold3/best_model.pth (mAP=0.5740)\n",
            "\n",
            "Epoch 11/15\n",
            "Train loss: 0.0052\n",
            "Val loss  : 0.0478\n",
            "Val mAP   : 0.5440\n",
            "LR        : 0.000159\n",
            "\n",
            "Epoch 12/15\n",
            "Train loss: 0.0030\n",
            "Val loss  : 0.0605\n",
            "Val mAP   : 0.5617\n",
            "LR        : 0.000094\n",
            "\n",
            "Epoch 13/15\n",
            "Train loss: 0.0013\n",
            "Val loss  : 0.0758\n",
            "Val mAP   : 0.5687\n",
            "LR        : 0.000043\n",
            "\n",
            "Epoch 14/15\n",
            "Train loss: 0.0006\n",
            "Val loss  : 0.0829\n",
            "Val mAP   : 0.5741\n",
            "LR        : 0.000011\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold3/best_model.pth (mAP=0.5741)\n",
            "\n",
            "Epoch 15/15\n",
            "Train loss: 0.0004\n",
            "Val loss  : 0.0846\n",
            "Val mAP   : 0.5736\n",
            "LR        : 0.000000\n",
            "\n",
            "Training finished.\n",
            "Best val mAP on fold 3: 0.5741\n",
            "Best model path: /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold3/best_model.pth\n",
            "History saved to: /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold3/history.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m src.train.super_images_baseline_CBfocal \\\n",
        "  --csv_path \"/content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\" \\\n",
        "  --models_dir \"/content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal\" \\\n",
        "  --fold 4 \\\n",
        "  --epochs 15 \\\n",
        "  --batch_size 4 \\\n",
        "  --lr 5e-4 \\\n",
        "  --model_name \"convnext_base\" \\\n",
        "  --img_size 1344 \\\n",
        "  --num_workers 12"
      ],
      "metadata": {
        "id": "qdysIR70vyfJ",
        "outputId": "f7b7b8a9-4fd2-4984-9b1f-a4d173a08cb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using device: cuda\n",
            "[INFO] Loading CSV from /content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\n",
            "[INFO] Inferred num_classes = 17\n",
            "[INFO] Fold 4: train samples = 2322, val samples = 559\n",
            "[INFO] Class counts (train) : [425, 641, 410, 343, 316, 139, 199, 184, 144, 105, 171, 83, 60, 33, 31, 81, 25]\n",
            "[INFO] Train batches: 581, Val batches: 140\n",
            "[INFO] Creating backbone: convnext_base\n",
            "[INFO] Using Class-Balanced Focal Loss\n",
            "\n",
            "Epoch 1/15\n",
            "Train loss: 0.0403\n",
            "Val loss  : 0.0387\n",
            "Val mAP   : 0.3553\n",
            "LR        : 0.000076\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold4/best_model.pth (mAP=0.3553)\n",
            "\n",
            "Epoch 2/15\n",
            "Train loss: 0.0328\n",
            "Val loss  : 0.0339\n",
            "Val mAP   : 0.4078\n",
            "LR        : 0.000218\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold4/best_model.pth (mAP=0.4078)\n",
            "\n",
            "Epoch 3/15\n",
            "Train loss: 0.0306\n",
            "Val loss  : 0.0543\n",
            "Val mAP   : 0.4046\n",
            "LR        : 0.000380\n",
            "\n",
            "Epoch 4/15\n",
            "Train loss: 0.0299\n",
            "Val loss  : 0.0352\n",
            "Val mAP   : 0.3600\n",
            "LR        : 0.000486\n",
            "\n",
            "Epoch 5/15\n",
            "Train loss: 0.0278\n",
            "Val loss  : 0.0355\n",
            "Val mAP   : 0.4003\n",
            "LR        : 0.000497\n",
            "\n",
            "Epoch 6/15\n",
            "Train loss: 0.0259\n",
            "Val loss  : 0.0320\n",
            "Val mAP   : 0.4325\n",
            "LR        : 0.000475\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold4/best_model.pth (mAP=0.4325)\n",
            "\n",
            "Epoch 7/15\n",
            "Train loss: 0.0240\n",
            "Val loss  : 0.0333\n",
            "Val mAP   : 0.4407\n",
            "LR        : 0.000433\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold4/best_model.pth (mAP=0.4407)\n",
            "\n",
            "Epoch 8/15\n",
            "Train loss: 0.0203\n",
            "Val loss  : 0.0381\n",
            "Val mAP   : 0.4501\n",
            "LR        : 0.000375\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold4/best_model.pth (mAP=0.4501)\n",
            "\n",
            "Epoch 9/15\n",
            "Train loss: 0.0136\n",
            "Val loss  : 0.0444\n",
            "Val mAP   : 0.4588\n",
            "LR        : 0.000306\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold4/best_model.pth (mAP=0.4588)\n",
            "\n",
            "Epoch 10/15\n",
            "Train loss: 0.0099\n",
            "Val loss  : 0.0483\n",
            "Val mAP   : 0.4627\n",
            "LR        : 0.000231\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold4/best_model.pth (mAP=0.4627)\n",
            "\n",
            "Epoch 11/15\n",
            "Train loss: 0.0047\n",
            "Val loss  : 0.0589\n",
            "Val mAP   : 0.4826\n",
            "LR        : 0.000159\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold4/best_model.pth (mAP=0.4826)\n",
            "\n",
            "Epoch 12/15\n",
            "Train loss: 0.0026\n",
            "Val loss  : 0.0783\n",
            "Val mAP   : 0.4864\n",
            "LR        : 0.000094\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold4/best_model.pth (mAP=0.4864)\n",
            "\n",
            "Epoch 13/15\n",
            "Train loss: 0.0012\n",
            "Val loss  : 0.0890\n",
            "Val mAP   : 0.4931\n",
            "LR        : 0.000043\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold4/best_model.pth (mAP=0.4931)\n",
            "\n",
            "Epoch 14/15\n",
            "Train loss: 0.0005\n",
            "Val loss  : 0.1008\n",
            "Val mAP   : 0.4946\n",
            "LR        : 0.000011\n",
            "New best model saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold4/best_model.pth (mAP=0.4946)\n",
            "\n",
            "Epoch 15/15\n",
            "Train loss: 0.0003\n",
            "Val loss  : 0.1018\n",
            "Val mAP   : 0.4943\n",
            "LR        : 0.000000\n",
            "\n",
            "Training finished.\n",
            "Best val mAP on fold 4: 0.4946\n",
            "Best model path: /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold4/best_model.pth\n",
            "History saved to: /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold4/history.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Post traitement des résultats"
      ],
      "metadata": {
        "id": "NVubguQAwHPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# À adapter si besoin\n",
        "MODELS_DIR = \"/content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal\"\n",
        "MODEL_NAME = \"convnext_base_CB-Focal\"\n",
        "NUM_FOLDS = 5  # folds 0 à 4\n",
        "\n",
        "all_results = []\n",
        "\n",
        "for fold in range(NUM_FOLDS):\n",
        "    fold_dir = os.path.join(MODELS_DIR, f\"{MODEL_NAME}_fold{fold}\")\n",
        "    history_path = os.path.join(fold_dir, \"history.json\")\n",
        "\n",
        "    if not os.path.exists(history_path):\n",
        "        print(f\"[WARN] history.json manquant pour le fold {fold} : {history_path}\")\n",
        "        continue\n",
        "\n",
        "    with open(history_path, \"r\") as f:\n",
        "        history = json.load(f)\n",
        "\n",
        "    df = pd.DataFrame(history)\n",
        "\n",
        "    # index de la meilleure mAP\n",
        "    best_idx = df[\"val_mAP\"].idxmax()\n",
        "    best_row = df.loc[best_idx]\n",
        "\n",
        "    best_map = float(best_row[\"val_mAP\"])\n",
        "    best_epoch = int(best_row[\"epoch\"])\n",
        "    best_train_loss = float(best_row[\"train_loss\"])\n",
        "    best_val_loss = float(best_row[\"val_loss\"])\n",
        "\n",
        "    print(f\"Fold {fold} → best mAP = {best_map:.4f} à l'epoch {best_epoch} \"\n",
        "          f\"(train_loss={best_train_loss:.4f}, val_loss={best_val_loss:.4f})\")\n",
        "\n",
        "    all_results.append({\n",
        "        \"fold\": fold,\n",
        "        \"best_epoch\": best_epoch,\n",
        "        \"best_val_mAP\": best_map,\n",
        "        \"train_loss_at_best\": best_train_loss,\n",
        "        \"val_loss_at_best\": best_val_loss,\n",
        "    })\n",
        "\n",
        "# Tableau récap global\n",
        "results_df = pd.DataFrame(all_results).sort_values(\"fold\").reset_index(drop=True)\n",
        "print(\"\\n=== Récap par fold ===\")\n",
        "display(results_df)\n",
        "\n",
        "if len(results_df) > 0:\n",
        "    mean_map = results_df[\"best_val_mAP\"].mean()\n",
        "    std_map = results_df[\"best_val_mAP\"].std()\n",
        "    print(f\"\\nmAP moyenne sur {len(results_df)} folds = {mean_map:.4f} ± {std_map:.4f}\")\n"
      ],
      "metadata": {
        "id": "cR9dD8hVv1A3",
        "outputId": "023e64ae-9d31-432a-d368-d5ef7deb9ebb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] history.json manquant pour le fold 0 : /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_CB-Focal_fold0/history.json\n",
            "[WARN] history.json manquant pour le fold 1 : /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_CB-Focal_fold1/history.json\n",
            "[WARN] history.json manquant pour le fold 2 : /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_CB-Focal_fold2/history.json\n",
            "[WARN] history.json manquant pour le fold 3 : /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_CB-Focal_fold3/history.json\n",
            "[WARN] history.json manquant pour le fold 4 : /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_CB-Focal_fold4/history.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'fold'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-93548871.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# Tableau récap global\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mresults_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fold\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n=== Récap par fold ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   7187\u001b[0m             \u001b[0;31m# len(by) == 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7189\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7191\u001b[0m             \u001b[0;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'fold'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "MODELS_DIR = \"/content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal\"\n",
        "MODEL_NAME = \"convnext_base\"\n",
        "NUM_FOLDS = 5  # 0 à 4\n",
        "\n",
        "for fold in range(NUM_FOLDS):\n",
        "    fold_dir = os.path.join(MODELS_DIR, f\"{MODEL_NAME}_fold{fold}\")\n",
        "    history_path = os.path.join(fold_dir, \"history.json\")\n",
        "\n",
        "    if not os.path.exists(history_path):\n",
        "        print(f\"[WARN] history.json manquant pour le fold {fold} : {history_path}\")\n",
        "        continue\n",
        "\n",
        "    with open(history_path, \"r\") as f:\n",
        "        history = json.load(f)\n",
        "\n",
        "    df = pd.DataFrame(history)\n",
        "\n",
        "    # --------- Courbe Loss train / val ---------\n",
        "    plt.figure()\n",
        "    plt.plot(df[\"epoch\"], df[\"train_loss\"], label=\"Train loss\")\n",
        "    plt.plot(df[\"epoch\"], df[\"val_loss\"], label=\"Val loss\")\n",
        "    plt.title(f\"Fold {fold} - Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # --------- Courbe mAP validation ---------\n",
        "    plt.figure()\n",
        "    plt.plot(df[\"epoch\"], df[\"val_mAP\"])\n",
        "    plt.title(f\"Fold {fold} - Validation mAP\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"mAP\")\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "ENQWXiIwwakC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K9tId8qcwcpP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}