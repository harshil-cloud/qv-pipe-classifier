{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Étape 3 – Entraînement baseline sur super-images 3×3 (Colab Pro+)\n",
        "\n",
        "Ce notebook entraîne un classifieur multi-label sur des super-images 3×3 construites à partir de 9 frames par vidéo.\n",
        "La logique d’entraînement est la même que pour l’Étape 2 (baseline framewise) :\n",
        "\n",
        "- Le code est dans `/content/qv-pipe-classifier`\n",
        "- Les données (CSV + super-images) sont sur Google Drive\n",
        "- Les modèles entraînés et l’historique sont sauvegardés dans `.../models/super_images_convnext`\n"
      ],
      "metadata": {
        "id": "UEnXMNAhFmPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vérifier le GPU Colab disponible\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "bQXOJR2qFr9v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d04ab612-975f-4946-d16a-3fdb49920a5d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Nov 30 09:04:27 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0             45W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Monter Google Drive (données + sorties des modèles)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "0MtVXvVuFwW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30ffcc09-e9ff-4645-91fb-fd3d7317a328"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cloner dépôt dans /content"
      ],
      "metadata": {
        "id": "svxfbz8hZ7Rp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clonage du dépôt dans /content (première fois dans cette session)\n",
        "%cd /content\n",
        "\n",
        "!git clone https://github.com/Simon-VDC/qv-pipe-classifier.git\n",
        "%cd qv-pipe-classifier\n",
        "\n",
        "!ls\n"
      ],
      "metadata": {
        "id": "bsR6NQxAFzJJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba3c4ac5-8d58-41ab-a61d-c2807f118e3b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'qv-pipe-classifier'...\n",
            "remote: Enumerating objects: 377, done.\u001b[K\n",
            "remote: Counting objects: 100% (209/209), done.\u001b[K\n",
            "remote: Compressing objects: 100% (177/177), done.\u001b[K\n",
            "remote: Total 377 (delta 96), reused 110 (delta 24), pack-reused 168 (from 1)\u001b[K\n",
            "Receiving objects: 100% (377/377), 845.88 KiB | 7.69 MiB/s, done.\n",
            "Resolving deltas: 100% (181/181), done.\n",
            "/content/qv-pipe-classifier\n",
            "CONFIG.md      docs\t\texp\t   project_tree.txt  requirements\n",
            "data\t       ENVIRONMENT.md\tLICENSE    README.md\t     scripts\n",
            "DATA_NOTES.md  environment.yml\tnotebooks  reports\t     src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Si le dépôt est déjà cloné, le mettre à jour\n",
        "%cd /content/qv-pipe-classifier\n",
        "!git pull"
      ],
      "metadata": {
        "id": "DnqmkH_sIjMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5ff62d4-1e82-4a2c-d83f-bb0569127a68"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/qv-pipe-classifier\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation des dépendances"
      ],
      "metadata": {
        "id": "_SED-fu_Z3Tk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installer les dépendances Step 2\n",
        "!pip install -r requirements/step3_training.txt\n"
      ],
      "metadata": {
        "id": "qBCmoMkxI1XN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24cf56b6-6e42-4f6c-e6f9-7cf651a4140b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements/step3_training.txt (line 2)) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from -r requirements/step3_training.txt (line 3)) (0.24.0+cu126)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (from -r requirements/step3_training.txt (line 4)) (1.0.22)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements/step3_training.txt (line 5)) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements/step3_training.txt (line 6)) (2.2.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from -r requirements/step3_training.txt (line 7)) (11.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r requirements/step3_training.txt (line 8)) (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (3.5.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm->-r requirements/step3_training.txt (line 4)) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm->-r requirements/step3_training.txt (line 4)) (0.36.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm->-r requirements/step3_training.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements/step3_training.txt (line 6)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements/step3_training.txt (line 6)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements/step3_training.txt (line 6)) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements/step3_training.txt (line 8)) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements/step3_training.txt (line 8)) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements/step3_training.txt (line 8)) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements/step3_training.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r requirements/step3_training.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm->-r requirements/step3_training.txt (line 4)) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm->-r requirements/step3_training.txt (line 4)) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm->-r requirements/step3_training.txt (line 4)) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm->-r requirements/step3_training.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r requirements/step3_training.txt (line 2)) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm->-r requirements/step3_training.txt (line 4)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm->-r requirements/step3_training.txt (line 4)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm->-r requirements/step3_training.txt (line 4)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm->-r requirements/step3_training.txt (line 4)) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration des dossiers de données et de modèles\n",
        "\n",
        "Les données (CSV + super-images) sont stockées sur Google Drive.  \n",
        "Les modèles entraînés et l’historique pour l’Étape 3 seront sauvegardés dans :\n",
        "\n",
        "- `models/super_images_convnext/fold_*/best.pth`\n",
        "- `models/super_images_convnext/fold_*/history.json`"
      ],
      "metadata": {
        "id": "9hhPOLN1ZwMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Dossier racine des données sur Google Drive\n",
        "DATA_BASE_DIR = \"/content/drive/MyDrive/QV Pipe\"  # adapter si nécessaire\n",
        "\n",
        "# CSV des splits pour les super-images (doit contenir : video_stem, superimage_path, labels_str, fold)\n",
        "SPLITS_CSV = os.path.join(DATA_BASE_DIR, \"data/splits/super_images_3x3_folds_colab.csv\")\n",
        "\n",
        "# Dossier de sortie pour les modèles et l'historique (même logique que baseline Étape 2)\n",
        "MODELS_DIR = os.path.join(DATA_BASE_DIR, \"models/super_images_convnext\")\n",
        "\n",
        "print(\"SPLITS_CSV:\", SPLITS_CSV)\n",
        "print(\"MODELS_DIR:\", MODELS_DIR)\n"
      ],
      "metadata": {
        "id": "rBoisAN2I_M3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c9d723b-438e-4ca0-9fb9-7332b7ac54f2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SPLITS_CSV: /content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\n",
            "MODELS_DIR: /content/drive/MyDrive/QV Pipe/models/super_images_convnext\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correction du fichier splits pour colab"
      ],
      "metadata": {
        "id": "tunSGWAWeMwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Chemin du CSV original (celui que tu utilises actuellement)\n",
        "DATA_BASE_DIR = \"/content/drive/MyDrive/QV Pipe\"  # adapte si besoin\n",
        "ORIG_CSV = os.path.join(DATA_BASE_DIR, \"data/splits/super_images_3x3_folds.csv\")\n",
        "\n",
        "df = pd.read_csv(ORIG_CSV)\n",
        "print(\"Avant correction:\", df.loc[0, \"superimage_path\"])\n",
        "\n",
        "# 1) Si les chemins sont relatifs \"data/super_images/....\"\n",
        "# 2) Si le vrai dossier sur Drive est \"data/super_images_3x3\"\n",
        "#    et que tu veux des chemins ABSOLUS pour Colab\n",
        "\n",
        "def fix_path(p):\n",
        "    # remplace le dossier si besoin\n",
        "    p = str(p).replace(\"data/super_images/\", \"data/super_images_3x3/\")\n",
        "    # préfixe par le chemin de base sur le Drive\n",
        "    full = os.path.join(DATA_BASE_DIR, p)\n",
        "    return full\n",
        "\n",
        "df[\"superimage_path\"] = df[\"superimage_path\"].apply(fix_path)\n",
        "\n",
        "print(\"Après correction:\", df.loc[0, \"superimage_path\"])\n",
        "print(\"Existe sur le disque :\", os.path.exists(df.loc[0, \"superimage_path\"]))\n",
        "\n",
        "# Sauvegarde dans un nouveau CSV spécifique à Colab\n",
        "FIXED_CSV = os.path.join(DATA_BASE_DIR, \"data/splits/super_images_3x3_folds_colab.csv\")\n",
        "df.to_csv(FIXED_CSV, index=False)\n",
        "\n",
        "print(\"CSV corrigé sauvegardé dans :\", FIXED_CSV)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP2o__QweP0K",
        "outputId": "66007b7e-9a42-4934-e714-b5327a4d0c4e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avant correction: data/super_images/2019_3x3.jpg\n",
            "Après correction: /content/drive/MyDrive/QV Pipe/data/super_images_3x3/2019_3x3.jpg\n",
            "Existe sur le disque : True\n",
            "CSV corrigé sauvegardé dans : /content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vérification rapide du CSV de splits\n",
        "\n",
        "\n",
        "Vérifier que :\n",
        "- Le fichier CSV existe\n",
        "- La colonne `superimage_path` contient des chemins valides vers des fichiers PNG/JPEG stockés sur Google Drive"
      ],
      "metadata": {
        "id": "ZuNZGFg8aMK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "assert os.path.exists(SPLITS_CSV), f\"Fichier CSV introuvable : {SPLITS_CSV}\"\n",
        "\n",
        "df = pd.read_csv(SPLITS_CSV)\n",
        "print(\"CSV chargé, shape :\", df.shape)\n",
        "print(df.head())\n",
        "\n",
        "# Optionnel : vérifier le premier chemin d’image\n",
        "first_path = df.loc[0, \"superimage_path\"]\n",
        "print(\"Exemple de superimage_path :\", first_path)\n",
        "print(\"Existe sur le disque :\", os.path.exists(first_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfXNKgJ9aP81",
        "outputId": "b4f64267-6a95-421c-b1fc-1862f7cef1dd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV chargé, shape : (2881, 4)\n",
            "  video_stem                                    superimage_path labels_str  \\\n",
            "0       2019  /content/drive/MyDrive/QV Pipe/data/super_imag...          0   \n",
            "1        202  /content/drive/MyDrive/QV Pipe/data/super_imag...          0   \n",
            "2       2022  /content/drive/MyDrive/QV Pipe/data/super_imag...          0   \n",
            "3       2023  /content/drive/MyDrive/QV Pipe/data/super_imag...          0   \n",
            "4       2036  /content/drive/MyDrive/QV Pipe/data/super_imag...          0   \n",
            "\n",
            "   fold  \n",
            "0     0  \n",
            "1     4  \n",
            "2     2  \n",
            "3     2  \n",
            "4     0  \n",
            "Exemple de superimage_path : /content/drive/MyDrive/QV Pipe/data/super_images_3x3/2019_3x3.jpg\n",
            "Existe sur le disque : True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vérifier la disponibilité du GPU\n",
        "\n",
        "Vérifier que Colab utilise un GPU et afficher son nom.\n"
      ],
      "metadata": {
        "id": "-JRYThoSabGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(\"CUDA disponible :\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU :\", torch.cuda.get_device_name(0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xd1F2K8MafuO",
        "outputId": "de2b0167-9975-47a4-a8f6-1aeedb7938bd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA disponible : True\n",
            "GPU : NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dry run sur 1 fold (test rapide)\n",
        "\n",
        "Lancer un entraînement court (peu d’epochs, petit batch) sur un seul fold pour valider :\n",
        "- Le chargement des données depuis `super_images_3x3_folds.csv`\n",
        "- Le forward/backward du modèle\n",
        "- Le calcul de la loss et de la mAP\n",
        "- La sauvegarde du checkpoint et de l’historique dans `MODELS_DIR`"
      ],
      "metadata": {
        "id": "8tpr61N1JBDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/qv-pipe-classifier\n",
        "\n",
        "!python -m src.train.super_images_baseline \\\n",
        "  --splits_csv \"{SPLITS_CSV}\" \\\n",
        "  --models_dir \"{MODELS_DIR}\" \\\n",
        "  --fold 0 \\\n",
        "  --epochs 2 \\\n",
        "  --batch_size 2 \\\n",
        "  --lr 1e-3 \\\n",
        "  --model_name \"convnext_base\" \\\n",
        "  --num_workers 0 \\\n",
        "  --dry_run\n"
      ],
      "metadata": {
        "id": "7sOGovh9JIAh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86c34a41-ba61-409c-c0c2-605320e76c0c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/qv-pipe-classifier\n",
            "[INFO] Using device: cuda\n",
            "[INFO] Loading splits CSV from /content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\n",
            "[INFO] Found 2881 super-images avec labels.\n",
            "[INFO] Inferred num_classes = 17\n",
            "[INFO] Fold 0: train samples = 2303, val samples = 578\n",
            "[INFO] Train batches: 1152, Val batches: 289\n",
            "[INFO] Creating backbone: convnext_base\n",
            "[INFO] Running DRY RUN (one batch through the model)...\n",
            "Batch images shape: torch.Size([2, 3, 448, 448])\n",
            "Batch labels shape: torch.Size([2, 17])\n",
            "Logits shape: torch.Size([2, 17])\n",
            "[INFO] Dry run OK. Exiting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mini entrainement réel"
      ],
      "metadata": {
        "id": "iiKmIvYgixXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/qv-pipe-classifier\n",
        "\n",
        "!python -m src.train.super_images_baseline \\\n",
        "  --splits_csv \"{SPLITS_CSV}\" \\\n",
        "  --models_dir \"{MODELS_DIR}\" \\\n",
        "  --fold 0 \\\n",
        "  --epochs 2 \\\n",
        "  --batch_size 4 \\\n",
        "  --lr 1e-3 \\\n",
        "  --model_name \"convnext_base\" \\\n",
        "  --num_workers 4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8hbYXOCi0-Z",
        "outputId": "ed0cae9a-98e4-4231-9671-f18093976aa0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/qv-pipe-classifier\n",
            "[INFO] Using device: cuda\n",
            "[INFO] Loading splits CSV from /content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\n",
            "[INFO] Found 2881 super-images avec labels.\n",
            "[INFO] Inferred num_classes = 17\n",
            "[INFO] Fold 0: train samples = 2303, val samples = 578\n",
            "[INFO] Train batches: 576, Val batches: 145\n",
            "[INFO] Creating backbone: convnext_base\n",
            "\n",
            "Epoch 1/2\n",
            "Epoch 1: train_loss=0.2704, val_loss=0.2686, val_mAP=0.1047, lr=0.000500\n",
            "New best mAP = 0.1047 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 2/2\n",
            "Epoch 2: train_loss=0.2627, val_loss=0.2650, val_mAP=0.1049, lr=0.000000\n",
            "New best mAP = 0.1049 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Training finished.\n",
            "Best mAP on fold 0 = 0.1049\n",
            "Best model saved at: /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/best_model.pth\n",
            "History saved at:    /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/history.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrainement des 5 folds sur 20 epoch pour les superimage\n",
        "\n",
        "Une fois le dry run validé, lancer un entraînement simple sur un fold pour tester le modele."
      ],
      "metadata": {
        "id": "ZYj_MlneJKFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m src.train.super_images_baseline \\\n",
        "  --splits_csv \"{SPLITS_CSV}\" \\\n",
        "  --models_dir \"{MODELS_DIR}\" \\\n",
        "  --fold 0 \\\n",
        "  --epochs 20 \\\n",
        "  --batch_size 4 \\\n",
        "  --lr 1e-3 \\\n",
        "  --model_name \"convnext_base\" \\\n",
        "  --num_workers 12\n"
      ],
      "metadata": {
        "id": "Fdva3FFPJScK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e7577aa-5537-40e1-9ade-b0828e88920e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using device: cuda\n",
            "[INFO] Loading splits CSV from /content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\n",
            "[INFO] Found 2881 super-images avec labels.\n",
            "[INFO] Inferred num_classes = 17\n",
            "[INFO] Fold 0: train samples = 2303, val samples = 578\n",
            "[INFO] Train batches: 576, Val batches: 145\n",
            "[INFO] Creating backbone: convnext_base\n",
            "\n",
            "Epoch 1/20\n",
            "Epoch 1: train_loss=0.2704, val_loss=0.2686, val_mAP=0.1047, lr=0.000994\n",
            "New best mAP = 0.1047 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 2/20\n",
            "Epoch 2: train_loss=0.2646, val_loss=0.2655, val_mAP=0.1058, lr=0.000976\n",
            "New best mAP = 0.1058 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 3/20\n",
            "Epoch 3: train_loss=0.2631, val_loss=0.2666, val_mAP=0.0959, lr=0.000946\n",
            "\n",
            "Epoch 4/20\n",
            "Epoch 4: train_loss=0.2629, val_loss=0.2651, val_mAP=0.1001, lr=0.000905\n",
            "\n",
            "Epoch 5/20\n",
            "Epoch 5: train_loss=0.2626, val_loss=0.2634, val_mAP=0.1006, lr=0.000854\n",
            "\n",
            "Epoch 6/20\n",
            "Epoch 6: train_loss=0.2619, val_loss=0.2650, val_mAP=0.1008, lr=0.000794\n",
            "\n",
            "Epoch 7/20\n",
            "Epoch 7: train_loss=0.2621, val_loss=0.2651, val_mAP=0.1007, lr=0.000727\n",
            "\n",
            "Epoch 8/20\n",
            "Epoch 8: train_loss=0.2615, val_loss=0.2651, val_mAP=0.0991, lr=0.000655\n",
            "\n",
            "Epoch 9/20\n",
            "Epoch 9: train_loss=0.2606, val_loss=0.2624, val_mAP=0.1142, lr=0.000578\n",
            "New best mAP = 0.1142 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 10/20\n",
            "Epoch 10: train_loss=0.2590, val_loss=0.2633, val_mAP=0.1087, lr=0.000500\n",
            "\n",
            "Epoch 11/20\n",
            "Epoch 11: train_loss=0.2590, val_loss=0.2617, val_mAP=0.1047, lr=0.000422\n",
            "\n",
            "Epoch 12/20\n",
            "Epoch 12: train_loss=0.2583, val_loss=0.2625, val_mAP=0.1109, lr=0.000345\n",
            "\n",
            "Epoch 13/20\n",
            "Epoch 13: train_loss=0.2579, val_loss=0.2628, val_mAP=0.1070, lr=0.000273\n",
            "\n",
            "Epoch 14/20\n",
            "Epoch 14: train_loss=0.2573, val_loss=0.2620, val_mAP=0.1105, lr=0.000206\n",
            "\n",
            "Epoch 15/20\n",
            "Epoch 15: train_loss=0.2570, val_loss=0.2615, val_mAP=0.1108, lr=0.000146\n",
            "\n",
            "Epoch 16/20\n",
            "Epoch 16: train_loss=0.2564, val_loss=0.2620, val_mAP=0.1126, lr=0.000095\n",
            "\n",
            "Epoch 17/20\n",
            "Epoch 17: train_loss=0.2561, val_loss=0.2619, val_mAP=0.1115, lr=0.000054\n",
            "\n",
            "Epoch 18/20\n",
            "Epoch 18: train_loss=0.2559, val_loss=0.2619, val_mAP=0.1168, lr=0.000024\n",
            "New best mAP = 0.1168 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 19/20\n",
            "Epoch 19: train_loss=0.2555, val_loss=0.2616, val_mAP=0.1151, lr=0.000006\n",
            "\n",
            "Epoch 20/20\n",
            "Epoch 20: train_loss=0.2553, val_loss=0.2617, val_mAP=0.1150, lr=0.000000\n",
            "\n",
            "Training finished.\n",
            "Best mAP on fold 0 = 0.1168\n",
            "Best model saved at: /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/best_model.pth\n",
            "History saved at:    /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/history.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ConvNeXt-Base, super-images 3×3, BCE, lr=1e-3 → mAP ≈ 0.117 sur le fold 0."
      ],
      "metadata": {
        "id": "iDfBH4JxwDLV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stagne --> modele qui prend peu de risque\n",
        "\n"
      ],
      "metadata": {
        "id": "hWoPW1GLufP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/qv-pipe-classifier\n",
        "\n",
        "NEW_MODELS_DIR = \"/content/drive/MyDrive/QV Pipe/models/super_images_convnext_lr3e-3\"\n",
        "\n",
        "!python -m src.train.super_images_baseline \\\n",
        "  --splits_csv \"{SPLITS_CSV}\" \\\n",
        "  --models_dir \"{NEW_MODELS_DIR}\" \\\n",
        "  --fold 0 \\\n",
        "  --epochs 20 \\\n",
        "  --batch_size 4 \\\n",
        "  --lr 3e-3 \\\n",
        "  --model_name \"convnext_base\" \\\n",
        "  --num_workers 12\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnguVRqEvafv",
        "outputId": "8d5e72c3-9e04-4637-db99-7cbfa29ec2a8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/qv-pipe-classifier\n",
            "[INFO] Using device: cuda\n",
            "[INFO] Loading splits CSV from /content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\n",
            "[INFO] Found 2881 super-images avec labels.\n",
            "[INFO] Inferred num_classes = 17\n",
            "[INFO] Fold 0: train samples = 2303, val samples = 578\n",
            "[INFO] Train batches: 576, Val batches: 145\n",
            "[INFO] Creating backbone: convnext_base\n",
            "\n",
            "Epoch 1/20\n",
            "Epoch 1: train_loss=0.2731, val_loss=0.2695, val_mAP=0.1017, lr=0.002982\n",
            "New best mAP = 0.1017 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_lr3e-3/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 2/20\n",
            "Epoch 2: train_loss=0.2651, val_loss=0.2666, val_mAP=0.1063, lr=0.002927\n",
            "New best mAP = 0.1063 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_lr3e-3/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 3/20\n",
            "Epoch 3: train_loss=0.2638, val_loss=0.2671, val_mAP=0.0968, lr=0.002837\n",
            "\n",
            "Epoch 4/20\n",
            "Epoch 4: train_loss=0.2632, val_loss=0.2651, val_mAP=0.0960, lr=0.002714\n",
            "\n",
            "Epoch 5/20\n",
            "Epoch 5: train_loss=0.2626, val_loss=0.2646, val_mAP=0.0975, lr=0.002561\n",
            "\n",
            "Epoch 6/20\n",
            "Epoch 6: train_loss=0.2622, val_loss=0.2647, val_mAP=0.1024, lr=0.002382\n",
            "\n",
            "Epoch 7/20\n",
            "Epoch 7: train_loss=0.2622, val_loss=0.2656, val_mAP=0.1004, lr=0.002181\n",
            "\n",
            "Epoch 8/20\n",
            "Epoch 8: train_loss=0.2619, val_loss=0.2650, val_mAP=0.1021, lr=0.001964\n",
            "\n",
            "Epoch 9/20\n",
            "Epoch 9: train_loss=0.2617, val_loss=0.2643, val_mAP=0.0920, lr=0.001735\n",
            "\n",
            "Epoch 10/20\n",
            "Epoch 10: train_loss=0.2612, val_loss=0.2645, val_mAP=0.0955, lr=0.001500\n",
            "\n",
            "Epoch 11/20\n",
            "Epoch 11: train_loss=0.2615, val_loss=0.2642, val_mAP=0.0950, lr=0.001265\n",
            "\n",
            "Epoch 12/20\n",
            "Epoch 12: train_loss=0.2610, val_loss=0.2639, val_mAP=0.0935, lr=0.001036\n",
            "\n",
            "Epoch 13/20\n",
            "Epoch 13: train_loss=0.2609, val_loss=0.2640, val_mAP=0.0993, lr=0.000819\n",
            "\n",
            "Epoch 14/20\n",
            "Epoch 14: train_loss=0.2606, val_loss=0.2637, val_mAP=0.1015, lr=0.000618\n",
            "\n",
            "Epoch 15/20\n",
            "Epoch 15: train_loss=0.2604, val_loss=0.2635, val_mAP=0.1000, lr=0.000439\n",
            "\n",
            "Epoch 16/20\n",
            "Epoch 16: train_loss=0.2603, val_loss=0.2637, val_mAP=0.1003, lr=0.000286\n",
            "\n",
            "Epoch 17/20\n",
            "Epoch 17: train_loss=0.2602, val_loss=0.2635, val_mAP=0.1008, lr=0.000163\n",
            "\n",
            "Epoch 18/20\n",
            "Epoch 18: train_loss=0.2600, val_loss=0.2635, val_mAP=0.0969, lr=0.000073\n",
            "\n",
            "Epoch 19/20\n",
            "Epoch 19: train_loss=0.2599, val_loss=0.2635, val_mAP=0.0942, lr=0.000018\n",
            "\n",
            "Epoch 20/20\n",
            "Epoch 20: train_loss=0.2598, val_loss=0.2635, val_mAP=0.0941, lr=0.000000\n",
            "\n",
            "Training finished.\n",
            "Best mAP on fold 0 = 0.1063\n",
            "Best model saved at: /content/drive/MyDrive/QV Pipe/models/super_images_convnext_lr3e-3/convnext_base_fold0/best_model.pth\n",
            "History saved at:    /content/drive/MyDrive/QV Pipe/models/super_images_convnext_lr3e-3/convnext_base_fold0/history.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fonction de perte : passage de BCE à ASL\n",
        "\n",
        "Initialement, la baseline utilisait une perte BCEWithLogitsLoss classique, bien adaptée à la classification multi-label mais peu robuste au fort déséquilibre de classes du dataset QV Pipe (beaucoup de zéros, peu de positives par classe)."
      ],
      "metadata": {
        "id": "GCsklQnZ-gIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SPLITS_CSV = \"/content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\"\n",
        "\n",
        "# Nouveau dossier pour cette expérience (ASL + flip)\n",
        "MODELS_DIR = \"/content/drive/MyDrive/QV Pipe/models/super_images_convnext_ASL\""
      ],
      "metadata": {
        "id": "feifYCjQAqEV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m src.train.super_images_baseline \\\n",
        "  --splits_csv \"{SPLITS_CSV}\" \\\n",
        "  --models_dir \"{MODELS_DIR}\" \\\n",
        "  --fold 0 \\\n",
        "  --epochs 20 \\\n",
        "  --batch_size 4 \\\n",
        "  --lr 1e-3 \\\n",
        "  --model_name \"convnext_base\" \\\n",
        "  --num_workers 12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Al3QHVwQBDcn",
        "outputId": "af6a814d-b957-403e-dfd3-895dbd3bf88a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using device: cuda\n",
            "[INFO] Loading splits CSV from /content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\n",
            "[INFO] Found 2881 super-images avec labels.\n",
            "[INFO] Inferred num_classes = 17\n",
            "[INFO] Fold 0: train samples = 2303, val samples = 578\n",
            "[INFO] Train batches: 576, Val batches: 145\n",
            "[INFO] Creating backbone: convnext_base\n",
            "model.safetensors: 100% 354M/354M [00:01<00:00, 291MB/s]\n",
            "\n",
            "Epoch 1/20\n",
            "Epoch 1: train_loss=0.0766, val_loss=0.0753, val_mAP=0.1205, lr=0.000994\n",
            "New best mAP = 0.1205 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_ASL/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 2/20\n",
            "Epoch 2: train_loss=0.0749, val_loss=0.0749, val_mAP=0.1114, lr=0.000976\n",
            "\n",
            "Epoch 3/20\n",
            "Epoch 3: train_loss=0.0744, val_loss=0.0753, val_mAP=0.1131, lr=0.000946\n",
            "\n",
            "Epoch 4/20\n",
            "Epoch 4: train_loss=0.0743, val_loss=0.0751, val_mAP=0.1029, lr=0.000905\n",
            "\n",
            "Epoch 5/20\n",
            "Epoch 5: train_loss=0.0744, val_loss=0.0749, val_mAP=0.1030, lr=0.000854\n",
            "\n",
            "Epoch 6/20\n",
            "Epoch 6: train_loss=0.0742, val_loss=0.0747, val_mAP=0.1095, lr=0.000794\n",
            "\n",
            "Epoch 7/20\n",
            "Epoch 7: train_loss=0.0741, val_loss=0.0747, val_mAP=0.1115, lr=0.000727\n",
            "\n",
            "Epoch 8/20\n",
            "Epoch 8: train_loss=0.0739, val_loss=0.0746, val_mAP=0.1124, lr=0.000655\n",
            "\n",
            "Epoch 9/20\n",
            "Epoch 9: train_loss=0.0738, val_loss=0.0745, val_mAP=0.1098, lr=0.000578\n",
            "\n",
            "Epoch 10/20\n",
            "Epoch 10: train_loss=0.0736, val_loss=0.0745, val_mAP=0.1157, lr=0.000500\n",
            "\n",
            "Epoch 11/20\n",
            "Epoch 11: train_loss=0.0743, val_loss=0.0745, val_mAP=0.1068, lr=0.000422\n",
            "\n",
            "Epoch 12/20\n",
            "Epoch 12: train_loss=0.0735, val_loss=0.0739, val_mAP=0.1179, lr=0.000345\n",
            "\n",
            "Epoch 13/20\n",
            "Epoch 13: train_loss=0.0729, val_loss=0.0736, val_mAP=0.1291, lr=0.000273\n",
            "New best mAP = 0.1291 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_ASL/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 14/20\n",
            "Epoch 14: train_loss=0.0725, val_loss=0.0733, val_mAP=0.1304, lr=0.000206\n",
            "New best mAP = 0.1304 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_ASL/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 15/20\n",
            "Epoch 15: train_loss=0.0721, val_loss=0.0730, val_mAP=0.1389, lr=0.000146\n",
            "New best mAP = 0.1389 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_ASL/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 16/20\n",
            "Epoch 16: train_loss=0.0718, val_loss=0.0731, val_mAP=0.1383, lr=0.000095\n",
            "\n",
            "Epoch 17/20\n",
            "Epoch 17: train_loss=0.0714, val_loss=0.0726, val_mAP=0.1446, lr=0.000054\n",
            "New best mAP = 0.1446 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_ASL/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 18/20\n",
            "Epoch 18: train_loss=0.0710, val_loss=0.0725, val_mAP=0.1455, lr=0.000024\n",
            "New best mAP = 0.1455 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_ASL/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 19/20\n",
            "Epoch 19: train_loss=0.0707, val_loss=0.0724, val_mAP=0.1489, lr=0.000006\n",
            "New best mAP = 0.1489 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_ASL/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 20/20\n",
            "Epoch 20: train_loss=0.0706, val_loss=0.0725, val_mAP=0.1489, lr=0.000000\n",
            "\n",
            "Training finished.\n",
            "Best mAP on fold 0 = 0.1489\n",
            "Best model saved at: /content/drive/MyDrive/QV Pipe/models/super_images_convnext_ASL/convnext_base_fold0/best_model.pth\n",
            "History saved at:    /content/drive/MyDrive/QV Pipe/models/super_images_convnext_ASL/convnext_base_fold0/history.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sanity check"
      ],
      "metadata": {
        "id": "B6meOzHIKTxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "full_df = pd.read_csv(SPLITS_CSV)\n",
        "\n",
        "# On prend uniquement des samples de train pour fold 0 (par ex.)\n",
        "mini_df = full_df[full_df[\"fold\"] != 0].sample(n=32, random_state=42)\n",
        "\n",
        "mini_csv_path = \"/content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_mini_overfit.csv\"\n",
        "mini_df.to_csv(mini_csv_path, index=False)\n",
        "\n",
        "mini_df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DZXA0qhpKR59",
        "outputId": "680f9070-85c4-490a-af28-c403f4307c0c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     video_stem                                    superimage_path labels_str  \\\n",
              "1172     d16428  /content/drive/MyDrive/QV Pipe/data/super_imag...          3   \n",
              "1614     d20926  /content/drive/MyDrive/QV Pipe/data/super_imag...          9   \n",
              "1635     d21125  /content/drive/MyDrive/QV Pipe/data/super_imag...        1 7   \n",
              "1579     d20846  /content/drive/MyDrive/QV Pipe/data/super_imag...       1 10   \n",
              "590         460  /content/drive/MyDrive/QV Pipe/data/super_imag...          0   \n",
              "\n",
              "      fold  \n",
              "1172     1  \n",
              "1614     3  \n",
              "1635     4  \n",
              "1579     3  \n",
              "590      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46712199-e97a-4804-a492-8a9de3d65437\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_stem</th>\n",
              "      <th>superimage_path</th>\n",
              "      <th>labels_str</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1172</th>\n",
              "      <td>d16428</td>\n",
              "      <td>/content/drive/MyDrive/QV Pipe/data/super_imag...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1614</th>\n",
              "      <td>d20926</td>\n",
              "      <td>/content/drive/MyDrive/QV Pipe/data/super_imag...</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1635</th>\n",
              "      <td>d21125</td>\n",
              "      <td>/content/drive/MyDrive/QV Pipe/data/super_imag...</td>\n",
              "      <td>1 7</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1579</th>\n",
              "      <td>d20846</td>\n",
              "      <td>/content/drive/MyDrive/QV Pipe/data/super_imag...</td>\n",
              "      <td>1 10</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>590</th>\n",
              "      <td>460</td>\n",
              "      <td>/content/drive/MyDrive/QV Pipe/data/super_imag...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46712199-e97a-4804-a492-8a9de3d65437')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-46712199-e97a-4804-a492-8a9de3d65437 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-46712199-e97a-4804-a492-8a9de3d65437');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2cda841a-2ea4-4274-8995-bd9aea92a0c6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2cda841a-2ea4-4274-8995-bd9aea92a0c6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2cda841a-2ea4-4274-8995-bd9aea92a0c6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "mini_df",
              "summary": "{\n  \"name\": \"mini_df\",\n  \"rows\": 32,\n  \"fields\": [\n    {\n      \"column\": \"video_stem\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 32,\n        \"samples\": [\n          \"25162\",\n          \"3654\",\n          \"d7298\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"superimage_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 32,\n        \"samples\": [\n          \"/content/drive/MyDrive/QV Pipe/data/super_images_3x3/25162_3x3.jpg\",\n          \"/content/drive/MyDrive/QV Pipe/data/super_images_3x3/3654_3x3.jpg\",\n          \"/content/drive/MyDrive/QV Pipe/data/super_images_3x3/d7298_3x3.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels_str\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 23,\n        \"samples\": [\n          \"2 4 13\",\n          \"3 6 8 15\",\n          \"3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fold\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3,\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from src.train.super_images_baseline import parse_labels_str\n",
        "\n",
        "df = pd.read_csv(SPLITS_CSV)\n",
        "\n",
        "# Convertit labels_str en listes d'indices\n",
        "labels_lists = df[\"labels_str\"].apply(parse_labels_str).tolist()\n",
        "\n",
        "# Nombre de classes inféré comme dans le script\n",
        "all_labels = []\n",
        "for lst in labels_lists:\n",
        "    all_labels.extend(lst)\n",
        "num_classes = max(all_labels) + 1\n",
        "print(\"num_classes =\", num_classes)\n",
        "\n",
        "# Comptage du nombre de vidéos positives par classe\n",
        "counts = np.zeros(num_classes, dtype=int)\n",
        "for lst in labels_lists:\n",
        "    for c in lst:\n",
        "        if 0 <= c < num_classes:\n",
        "            counts[c] += 1\n",
        "\n",
        "for cls_idx, n in enumerate(counts):\n",
        "    print(f\"Classe {cls_idx:2d} : {n} vidéos positives\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faoA0H-oK5Pf",
        "outputId": "b5b9adb5-92bd-4e40-d2f0-3d94ce5d97bd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_classes = 17\n",
            "Classe  0 : 538 vidéos positives\n",
            "Classe  1 : 791 vidéos positives\n",
            "Classe  2 : 509 vidéos positives\n",
            "Classe  3 : 420 vidéos positives\n",
            "Classe  4 : 388 vidéos positives\n",
            "Classe  5 : 169 vidéos positives\n",
            "Classe  6 : 243 vidéos positives\n",
            "Classe  7 : 220 vidéos positives\n",
            "Classe  8 : 172 vidéos positives\n",
            "Classe  9 : 131 vidéos positives\n",
            "Classe 10 : 204 vidéos positives\n",
            "Classe 11 : 100 vidéos positives\n",
            "Classe 12 : 79 vidéos positives\n",
            "Classe 13 : 37 vidéos positives\n",
            "Classe 14 : 40 vidéos positives\n",
            "Classe 15 : 102 vidéos positives\n",
            "Classe 16 : 33 vidéos positives\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xowCCF82Fs7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from src.train.super_images_baseline import parse_labels_str  # même fonction que framewise\n",
        "\n",
        "SPLITS_CSV = \"/content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\"\n",
        "df = pd.read_csv(SPLITS_CSV)\n",
        "\n",
        "labels_lists = df[\"labels_str\"].apply(parse_labels_str).tolist()\n",
        "\n",
        "all_labels = []\n",
        "for lst in labels_lists:\n",
        "    all_labels.extend(lst)\n",
        "\n",
        "num_classes = max(all_labels) + 1 if len(all_labels) > 0 else 0\n",
        "print(\"num_classes =\", num_classes)\n",
        "\n",
        "counts = np.zeros(num_classes, dtype=int)\n",
        "for lst in labels_lists:\n",
        "    for c in lst:\n",
        "        if 0 <= c < num_classes:\n",
        "            counts[c] += 1\n",
        "\n",
        "for cls_idx, n in enumerate(counts):\n",
        "    print(f\"Classe {cls_idx:2d} : {n} super-images positives\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9ZahzmjNGGC",
        "outputId": "5b13443e-a1ed-4d83-e24f-98902aa35e5a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_classes = 17\n",
            "Classe  0 : 538 super-images positives\n",
            "Classe  1 : 791 super-images positives\n",
            "Classe  2 : 509 super-images positives\n",
            "Classe  3 : 420 super-images positives\n",
            "Classe  4 : 388 super-images positives\n",
            "Classe  5 : 169 super-images positives\n",
            "Classe  6 : 243 super-images positives\n",
            "Classe  7 : 220 super-images positives\n",
            "Classe  8 : 172 super-images positives\n",
            "Classe  9 : 131 super-images positives\n",
            "Classe 10 : 204 super-images positives\n",
            "Classe 11 : 100 super-images positives\n",
            "Classe 12 : 79 super-images positives\n",
            "Classe 13 : 37 super-images positives\n",
            "Classe 14 : 40 super-images positives\n",
            "Classe 15 : 102 super-images positives\n",
            "Classe 16 : 33 super-images positives\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_empty = sum(len(lst) == 0 for lst in labels_lists)\n",
        "print(\"Super-images sans aucun label :\", num_empty, \"/\", len(labels_lists))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xy5NnB5-NGlm",
        "outputId": "51ced89f-c120-40b7-997f-1090b7a0e29c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Super-images sans aucun label : 0 / 2881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hL6RuJuHNOt9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}