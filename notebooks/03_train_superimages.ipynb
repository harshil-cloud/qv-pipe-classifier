{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Étape 3 – Entraînement baseline sur super-images 3×3 (Colab Pro+)\n",
        "\n",
        "Ce notebook entraîne un classifieur multi-label sur des super-images 3×3 construites à partir de 9 frames par vidéo.\n",
        "La logique d’entraînement est la même que pour l’Étape 2 (baseline framewise) :\n",
        "\n",
        "- Le code est dans `/content/qv-pipe-classifier`\n",
        "- Les données (CSV + super-images) sont sur Google Drive\n",
        "- Les modèles entraînés et l’historique sont sauvegardés dans `.../models/super_images_convnext`\n"
      ],
      "metadata": {
        "id": "UEnXMNAhFmPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vérifier le GPU Colab disponible\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "bQXOJR2qFr9v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09743775-7476-461e-dbff-9b3f86542304"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Nov 29 21:36:29 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0             43W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Monter Google Drive (données + sorties des modèles)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "0MtVXvVuFwW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4d8bdb2-29ad-48a9-d356-dc9c04748bf3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cloner dépôt dans /content"
      ],
      "metadata": {
        "id": "svxfbz8hZ7Rp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clonage du dépôt dans /content (première fois dans cette session)\n",
        "%cd /content\n",
        "\n",
        "!git clone https://github.com/Simon-VDC/qv-pipe-classifier.git\n",
        "%cd qv-pipe-classifier\n",
        "\n",
        "!ls\n"
      ],
      "metadata": {
        "id": "bsR6NQxAFzJJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2ca9eb5-5776-49f0-dd59-ca3866a52919"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'qv-pipe-classifier'...\n",
            "remote: Enumerating objects: 359, done.\u001b[K\n",
            "remote: Counting objects: 100% (191/191), done.\u001b[K\n",
            "remote: Compressing objects: 100% (161/161), done.\u001b[K\n",
            "remote: Total 359 (delta 83), reused 106 (delta 22), pack-reused 168 (from 1)\u001b[K\n",
            "Receiving objects: 100% (359/359), 834.98 KiB | 10.31 MiB/s, done.\n",
            "Resolving deltas: 100% (168/168), done.\n",
            "/content/qv-pipe-classifier\n",
            "CONFIG.md      docs\t\texp\t   project_tree.txt  requirements\n",
            "data\t       ENVIRONMENT.md\tLICENSE    README.md\t     scripts\n",
            "DATA_NOTES.md  environment.yml\tnotebooks  reports\t     src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Si le dépôt est déjà cloné, le mettre à jour\n",
        "%cd /content/qv-pipe-classifier\n",
        "!git pull"
      ],
      "metadata": {
        "id": "DnqmkH_sIjMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5ff62d4-1e82-4a2c-d83f-bb0569127a68"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/qv-pipe-classifier\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation des dépendances"
      ],
      "metadata": {
        "id": "_SED-fu_Z3Tk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installer les dépendances Step 2\n",
        "!pip install -r requirements/step3_training.txt\n"
      ],
      "metadata": {
        "id": "qBCmoMkxI1XN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cdf3d66-f568-45d1-e9a8-00b01f4d101f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements/step3_training.txt (line 2)) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from -r requirements/step3_training.txt (line 3)) (0.24.0+cu126)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (from -r requirements/step3_training.txt (line 4)) (1.0.22)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements/step3_training.txt (line 5)) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements/step3_training.txt (line 6)) (2.2.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from -r requirements/step3_training.txt (line 7)) (11.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r requirements/step3_training.txt (line 8)) (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements/step3_training.txt (line 2)) (3.5.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm->-r requirements/step3_training.txt (line 4)) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm->-r requirements/step3_training.txt (line 4)) (0.36.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm->-r requirements/step3_training.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements/step3_training.txt (line 6)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements/step3_training.txt (line 6)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements/step3_training.txt (line 6)) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements/step3_training.txt (line 8)) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements/step3_training.txt (line 8)) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements/step3_training.txt (line 8)) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements/step3_training.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r requirements/step3_training.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm->-r requirements/step3_training.txt (line 4)) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm->-r requirements/step3_training.txt (line 4)) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm->-r requirements/step3_training.txt (line 4)) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm->-r requirements/step3_training.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r requirements/step3_training.txt (line 2)) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm->-r requirements/step3_training.txt (line 4)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm->-r requirements/step3_training.txt (line 4)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm->-r requirements/step3_training.txt (line 4)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm->-r requirements/step3_training.txt (line 4)) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration des dossiers de données et de modèles\n",
        "\n",
        "Les données (CSV + super-images) sont stockées sur Google Drive.  \n",
        "Les modèles entraînés et l’historique pour l’Étape 3 seront sauvegardés dans :\n",
        "\n",
        "- `models/super_images_convnext/fold_*/best.pth`\n",
        "- `models/super_images_convnext/fold_*/history.json`"
      ],
      "metadata": {
        "id": "9hhPOLN1ZwMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Dossier racine des données sur Google Drive\n",
        "DATA_BASE_DIR = \"/content/drive/MyDrive/QV Pipe\"  # adapter si nécessaire\n",
        "\n",
        "# CSV des splits pour les super-images (doit contenir : video_stem, superimage_path, labels_str, fold)\n",
        "SPLITS_CSV = os.path.join(DATA_BASE_DIR, \"data/splits/super_images_3x3_folds_colab.csv\")\n",
        "\n",
        "# Dossier de sortie pour les modèles et l'historique (même logique que baseline Étape 2)\n",
        "MODELS_DIR = os.path.join(DATA_BASE_DIR, \"models/super_images_convnext\")\n",
        "\n",
        "print(\"SPLITS_CSV:\", SPLITS_CSV)\n",
        "print(\"MODELS_DIR:\", MODELS_DIR)\n"
      ],
      "metadata": {
        "id": "rBoisAN2I_M3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2b0c5c5-9a57-4a93-d041-9a097b0721ce"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SPLITS_CSV: /content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\n",
            "MODELS_DIR: /content/drive/MyDrive/QV Pipe/models/super_images_convnext\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correction du fichier splits pour colab"
      ],
      "metadata": {
        "id": "tunSGWAWeMwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Chemin du CSV original (celui que tu utilises actuellement)\n",
        "DATA_BASE_DIR = \"/content/drive/MyDrive/QV Pipe\"  # adapte si besoin\n",
        "ORIG_CSV = os.path.join(DATA_BASE_DIR, \"data/splits/super_images_3x3_folds.csv\")\n",
        "\n",
        "df = pd.read_csv(ORIG_CSV)\n",
        "print(\"Avant correction:\", df.loc[0, \"superimage_path\"])\n",
        "\n",
        "# 1) Si les chemins sont relatifs \"data/super_images/....\"\n",
        "# 2) Si le vrai dossier sur Drive est \"data/super_images_3x3\"\n",
        "#    et que tu veux des chemins ABSOLUS pour Colab\n",
        "\n",
        "def fix_path(p):\n",
        "    # remplace le dossier si besoin\n",
        "    p = str(p).replace(\"data/super_images/\", \"data/super_images_3x3/\")\n",
        "    # préfixe par le chemin de base sur le Drive\n",
        "    full = os.path.join(DATA_BASE_DIR, p)\n",
        "    return full\n",
        "\n",
        "df[\"superimage_path\"] = df[\"superimage_path\"].apply(fix_path)\n",
        "\n",
        "print(\"Après correction:\", df.loc[0, \"superimage_path\"])\n",
        "print(\"Existe sur le disque :\", os.path.exists(df.loc[0, \"superimage_path\"]))\n",
        "\n",
        "# Sauvegarde dans un nouveau CSV spécifique à Colab\n",
        "FIXED_CSV = os.path.join(DATA_BASE_DIR, \"data/splits/super_images_3x3_folds_colab.csv\")\n",
        "df.to_csv(FIXED_CSV, index=False)\n",
        "\n",
        "print(\"CSV corrigé sauvegardé dans :\", FIXED_CSV)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP2o__QweP0K",
        "outputId": "66007b7e-9a42-4934-e714-b5327a4d0c4e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avant correction: data/super_images/2019_3x3.jpg\n",
            "Après correction: /content/drive/MyDrive/QV Pipe/data/super_images_3x3/2019_3x3.jpg\n",
            "Existe sur le disque : True\n",
            "CSV corrigé sauvegardé dans : /content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vérification rapide du CSV de splits\n",
        "\n",
        "\n",
        "Vérifier que :\n",
        "- Le fichier CSV existe\n",
        "- La colonne `superimage_path` contient des chemins valides vers des fichiers PNG/JPEG stockés sur Google Drive"
      ],
      "metadata": {
        "id": "ZuNZGFg8aMK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "assert os.path.exists(SPLITS_CSV), f\"Fichier CSV introuvable : {SPLITS_CSV}\"\n",
        "\n",
        "df = pd.read_csv(SPLITS_CSV)\n",
        "print(\"CSV chargé, shape :\", df.shape)\n",
        "print(df.head())\n",
        "\n",
        "# Optionnel : vérifier le premier chemin d’image\n",
        "first_path = df.loc[0, \"superimage_path\"]\n",
        "print(\"Exemple de superimage_path :\", first_path)\n",
        "print(\"Existe sur le disque :\", os.path.exists(first_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfXNKgJ9aP81",
        "outputId": "b4f64267-6a95-421c-b1fc-1862f7cef1dd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV chargé, shape : (2881, 4)\n",
            "  video_stem                                    superimage_path labels_str  \\\n",
            "0       2019  /content/drive/MyDrive/QV Pipe/data/super_imag...          0   \n",
            "1        202  /content/drive/MyDrive/QV Pipe/data/super_imag...          0   \n",
            "2       2022  /content/drive/MyDrive/QV Pipe/data/super_imag...          0   \n",
            "3       2023  /content/drive/MyDrive/QV Pipe/data/super_imag...          0   \n",
            "4       2036  /content/drive/MyDrive/QV Pipe/data/super_imag...          0   \n",
            "\n",
            "   fold  \n",
            "0     0  \n",
            "1     4  \n",
            "2     2  \n",
            "3     2  \n",
            "4     0  \n",
            "Exemple de superimage_path : /content/drive/MyDrive/QV Pipe/data/super_images_3x3/2019_3x3.jpg\n",
            "Existe sur le disque : True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vérifier la disponibilité du GPU\n",
        "\n",
        "Vérifier que Colab utilise un GPU et afficher son nom.\n"
      ],
      "metadata": {
        "id": "-JRYThoSabGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(\"CUDA disponible :\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU :\", torch.cuda.get_device_name(0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xd1F2K8MafuO",
        "outputId": "3eb5cfea-6f41-4b91-aa69-da8501002811"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA disponible : True\n",
            "GPU : NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dry run sur 1 fold (test rapide)\n",
        "\n",
        "Lancer un entraînement court (peu d’epochs, petit batch) sur un seul fold pour valider :\n",
        "- Le chargement des données depuis `super_images_3x3_folds.csv`\n",
        "- Le forward/backward du modèle\n",
        "- Le calcul de la loss et de la mAP\n",
        "- La sauvegarde du checkpoint et de l’historique dans `MODELS_DIR`"
      ],
      "metadata": {
        "id": "8tpr61N1JBDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/qv-pipe-classifier\n",
        "\n",
        "!python -m src.train.super_images_baseline \\\n",
        "  --splits_csv \"{SPLITS_CSV}\" \\\n",
        "  --models_dir \"{MODELS_DIR}\" \\\n",
        "  --fold 0 \\\n",
        "  --epochs 2 \\\n",
        "  --batch_size 2 \\\n",
        "  --lr 1e-3 \\\n",
        "  --model_name \"convnext_base\" \\\n",
        "  --num_workers 0 \\\n",
        "  --dry_run\n"
      ],
      "metadata": {
        "id": "7sOGovh9JIAh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86c34a41-ba61-409c-c0c2-605320e76c0c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/qv-pipe-classifier\n",
            "[INFO] Using device: cuda\n",
            "[INFO] Loading splits CSV from /content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\n",
            "[INFO] Found 2881 super-images avec labels.\n",
            "[INFO] Inferred num_classes = 17\n",
            "[INFO] Fold 0: train samples = 2303, val samples = 578\n",
            "[INFO] Train batches: 1152, Val batches: 289\n",
            "[INFO] Creating backbone: convnext_base\n",
            "[INFO] Running DRY RUN (one batch through the model)...\n",
            "Batch images shape: torch.Size([2, 3, 448, 448])\n",
            "Batch labels shape: torch.Size([2, 17])\n",
            "Logits shape: torch.Size([2, 17])\n",
            "[INFO] Dry run OK. Exiting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mini entrainement réel"
      ],
      "metadata": {
        "id": "iiKmIvYgixXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/qv-pipe-classifier\n",
        "\n",
        "!python -m src.train.super_images_baseline \\\n",
        "  --splits_csv \"{SPLITS_CSV}\" \\\n",
        "  --models_dir \"{MODELS_DIR}\" \\\n",
        "  --fold 0 \\\n",
        "  --epochs 2 \\\n",
        "  --batch_size 4 \\\n",
        "  --lr 1e-3 \\\n",
        "  --model_name \"convnext_base\" \\\n",
        "  --num_workers 4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8hbYXOCi0-Z",
        "outputId": "ed0cae9a-98e4-4231-9671-f18093976aa0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/qv-pipe-classifier\n",
            "[INFO] Using device: cuda\n",
            "[INFO] Loading splits CSV from /content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\n",
            "[INFO] Found 2881 super-images avec labels.\n",
            "[INFO] Inferred num_classes = 17\n",
            "[INFO] Fold 0: train samples = 2303, val samples = 578\n",
            "[INFO] Train batches: 576, Val batches: 145\n",
            "[INFO] Creating backbone: convnext_base\n",
            "\n",
            "Epoch 1/2\n",
            "Epoch 1: train_loss=0.2704, val_loss=0.2686, val_mAP=0.1047, lr=0.000500\n",
            "New best mAP = 0.1047 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 2/2\n",
            "Epoch 2: train_loss=0.2627, val_loss=0.2650, val_mAP=0.1049, lr=0.000000\n",
            "New best mAP = 0.1049 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Training finished.\n",
            "Best mAP on fold 0 = 0.1049\n",
            "Best model saved at: /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/best_model.pth\n",
            "History saved at:    /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/history.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrainement des 5 folds sur 20 epoch pour les superimage\n",
        "\n",
        "Une fois le dry run validé, lancer un entraînement simple sur un fold pour tester le modele."
      ],
      "metadata": {
        "id": "ZYj_MlneJKFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m src.train.super_images_baseline \\\n",
        "  --splits_csv \"{SPLITS_CSV}\" \\\n",
        "  --models_dir \"{MODELS_DIR}\" \\\n",
        "  --fold 0 \\\n",
        "  --epochs 20 \\\n",
        "  --batch_size 4 \\\n",
        "  --lr 1e-3 \\\n",
        "  --model_name \"convnext_base\" \\\n",
        "  --num_workers 12\n"
      ],
      "metadata": {
        "id": "Fdva3FFPJScK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e7577aa-5537-40e1-9ade-b0828e88920e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using device: cuda\n",
            "[INFO] Loading splits CSV from /content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\n",
            "[INFO] Found 2881 super-images avec labels.\n",
            "[INFO] Inferred num_classes = 17\n",
            "[INFO] Fold 0: train samples = 2303, val samples = 578\n",
            "[INFO] Train batches: 576, Val batches: 145\n",
            "[INFO] Creating backbone: convnext_base\n",
            "\n",
            "Epoch 1/20\n",
            "Epoch 1: train_loss=0.2704, val_loss=0.2686, val_mAP=0.1047, lr=0.000994\n",
            "New best mAP = 0.1047 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 2/20\n",
            "Epoch 2: train_loss=0.2646, val_loss=0.2655, val_mAP=0.1058, lr=0.000976\n",
            "New best mAP = 0.1058 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 3/20\n",
            "Epoch 3: train_loss=0.2631, val_loss=0.2666, val_mAP=0.0959, lr=0.000946\n",
            "\n",
            "Epoch 4/20\n",
            "Epoch 4: train_loss=0.2629, val_loss=0.2651, val_mAP=0.1001, lr=0.000905\n",
            "\n",
            "Epoch 5/20\n",
            "Epoch 5: train_loss=0.2626, val_loss=0.2634, val_mAP=0.1006, lr=0.000854\n",
            "\n",
            "Epoch 6/20\n",
            "Epoch 6: train_loss=0.2619, val_loss=0.2650, val_mAP=0.1008, lr=0.000794\n",
            "\n",
            "Epoch 7/20\n",
            "Epoch 7: train_loss=0.2621, val_loss=0.2651, val_mAP=0.1007, lr=0.000727\n",
            "\n",
            "Epoch 8/20\n",
            "Epoch 8: train_loss=0.2615, val_loss=0.2651, val_mAP=0.0991, lr=0.000655\n",
            "\n",
            "Epoch 9/20\n",
            "Epoch 9: train_loss=0.2606, val_loss=0.2624, val_mAP=0.1142, lr=0.000578\n",
            "New best mAP = 0.1142 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 10/20\n",
            "Epoch 10: train_loss=0.2590, val_loss=0.2633, val_mAP=0.1087, lr=0.000500\n",
            "\n",
            "Epoch 11/20\n",
            "Epoch 11: train_loss=0.2590, val_loss=0.2617, val_mAP=0.1047, lr=0.000422\n",
            "\n",
            "Epoch 12/20\n",
            "Epoch 12: train_loss=0.2583, val_loss=0.2625, val_mAP=0.1109, lr=0.000345\n",
            "\n",
            "Epoch 13/20\n",
            "Epoch 13: train_loss=0.2579, val_loss=0.2628, val_mAP=0.1070, lr=0.000273\n",
            "\n",
            "Epoch 14/20\n",
            "Epoch 14: train_loss=0.2573, val_loss=0.2620, val_mAP=0.1105, lr=0.000206\n",
            "\n",
            "Epoch 15/20\n",
            "Epoch 15: train_loss=0.2570, val_loss=0.2615, val_mAP=0.1108, lr=0.000146\n",
            "\n",
            "Epoch 16/20\n",
            "Epoch 16: train_loss=0.2564, val_loss=0.2620, val_mAP=0.1126, lr=0.000095\n",
            "\n",
            "Epoch 17/20\n",
            "Epoch 17: train_loss=0.2561, val_loss=0.2619, val_mAP=0.1115, lr=0.000054\n",
            "\n",
            "Epoch 18/20\n",
            "Epoch 18: train_loss=0.2559, val_loss=0.2619, val_mAP=0.1168, lr=0.000024\n",
            "New best mAP = 0.1168 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 19/20\n",
            "Epoch 19: train_loss=0.2555, val_loss=0.2616, val_mAP=0.1151, lr=0.000006\n",
            "\n",
            "Epoch 20/20\n",
            "Epoch 20: train_loss=0.2553, val_loss=0.2617, val_mAP=0.1150, lr=0.000000\n",
            "\n",
            "Training finished.\n",
            "Best mAP on fold 0 = 0.1168\n",
            "Best model saved at: /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/best_model.pth\n",
            "History saved at:    /content/drive/MyDrive/QV Pipe/models/super_images_convnext/convnext_base_fold0/history.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ConvNeXt-Base, super-images 3×3, BCE, lr=1e-3 → mAP ≈ 0.117 sur le fold 0."
      ],
      "metadata": {
        "id": "iDfBH4JxwDLV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stagne --> modele qui prend peu de risque\n",
        "\n"
      ],
      "metadata": {
        "id": "hWoPW1GLufP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/qv-pipe-classifier\n",
        "\n",
        "NEW_MODELS_DIR = \"/content/drive/MyDrive/QV Pipe/models/super_images_convnext_lr3e-3\"\n",
        "\n",
        "!python -m src.train.super_images_baseline \\\n",
        "  --splits_csv \"{SPLITS_CSV}\" \\\n",
        "  --models_dir \"{NEW_MODELS_DIR}\" \\\n",
        "  --fold 0 \\\n",
        "  --epochs 20 \\\n",
        "  --batch_size 4 \\\n",
        "  --lr 3e-3 \\\n",
        "  --model_name \"convnext_base\" \\\n",
        "  --num_workers 12\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnguVRqEvafv",
        "outputId": "8d5e72c3-9e04-4637-db99-7cbfa29ec2a8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/qv-pipe-classifier\n",
            "[INFO] Using device: cuda\n",
            "[INFO] Loading splits CSV from /content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\n",
            "[INFO] Found 2881 super-images avec labels.\n",
            "[INFO] Inferred num_classes = 17\n",
            "[INFO] Fold 0: train samples = 2303, val samples = 578\n",
            "[INFO] Train batches: 576, Val batches: 145\n",
            "[INFO] Creating backbone: convnext_base\n",
            "\n",
            "Epoch 1/20\n",
            "Epoch 1: train_loss=0.2731, val_loss=0.2695, val_mAP=0.1017, lr=0.002982\n",
            "New best mAP = 0.1017 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_lr3e-3/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 2/20\n",
            "Epoch 2: train_loss=0.2651, val_loss=0.2666, val_mAP=0.1063, lr=0.002927\n",
            "New best mAP = 0.1063 → checkpoint saved at /content/drive/MyDrive/QV Pipe/models/super_images_convnext_lr3e-3/convnext_base_fold0/best_model.pth\n",
            "\n",
            "Epoch 3/20\n",
            "Epoch 3: train_loss=0.2638, val_loss=0.2671, val_mAP=0.0968, lr=0.002837\n",
            "\n",
            "Epoch 4/20\n",
            "Epoch 4: train_loss=0.2632, val_loss=0.2651, val_mAP=0.0960, lr=0.002714\n",
            "\n",
            "Epoch 5/20\n",
            "Epoch 5: train_loss=0.2626, val_loss=0.2646, val_mAP=0.0975, lr=0.002561\n",
            "\n",
            "Epoch 6/20\n",
            "Epoch 6: train_loss=0.2622, val_loss=0.2647, val_mAP=0.1024, lr=0.002382\n",
            "\n",
            "Epoch 7/20\n",
            "Epoch 7: train_loss=0.2622, val_loss=0.2656, val_mAP=0.1004, lr=0.002181\n",
            "\n",
            "Epoch 8/20\n",
            "Epoch 8: train_loss=0.2619, val_loss=0.2650, val_mAP=0.1021, lr=0.001964\n",
            "\n",
            "Epoch 9/20\n",
            "Epoch 9: train_loss=0.2617, val_loss=0.2643, val_mAP=0.0920, lr=0.001735\n",
            "\n",
            "Epoch 10/20\n",
            "Epoch 10: train_loss=0.2612, val_loss=0.2645, val_mAP=0.0955, lr=0.001500\n",
            "\n",
            "Epoch 11/20\n",
            "Epoch 11: train_loss=0.2615, val_loss=0.2642, val_mAP=0.0950, lr=0.001265\n",
            "\n",
            "Epoch 12/20\n",
            "Epoch 12: train_loss=0.2610, val_loss=0.2639, val_mAP=0.0935, lr=0.001036\n",
            "\n",
            "Epoch 13/20\n",
            "Epoch 13: train_loss=0.2609, val_loss=0.2640, val_mAP=0.0993, lr=0.000819\n",
            "\n",
            "Epoch 14/20\n",
            "Epoch 14: train_loss=0.2606, val_loss=0.2637, val_mAP=0.1015, lr=0.000618\n",
            "\n",
            "Epoch 15/20\n",
            "Epoch 15: train_loss=0.2604, val_loss=0.2635, val_mAP=0.1000, lr=0.000439\n",
            "\n",
            "Epoch 16/20\n",
            "Epoch 16: train_loss=0.2603, val_loss=0.2637, val_mAP=0.1003, lr=0.000286\n",
            "\n",
            "Epoch 17/20\n",
            "Epoch 17: train_loss=0.2602, val_loss=0.2635, val_mAP=0.1008, lr=0.000163\n",
            "\n",
            "Epoch 18/20\n",
            "Epoch 18: train_loss=0.2600, val_loss=0.2635, val_mAP=0.0969, lr=0.000073\n",
            "\n",
            "Epoch 19/20\n",
            "Epoch 19: train_loss=0.2599, val_loss=0.2635, val_mAP=0.0942, lr=0.000018\n",
            "\n",
            "Epoch 20/20\n",
            "Epoch 20: train_loss=0.2598, val_loss=0.2635, val_mAP=0.0941, lr=0.000000\n",
            "\n",
            "Training finished.\n",
            "Best mAP on fold 0 = 0.1063\n",
            "Best model saved at: /content/drive/MyDrive/QV Pipe/models/super_images_convnext_lr3e-3/convnext_base_fold0/best_model.pth\n",
            "History saved at:    /content/drive/MyDrive/QV Pipe/models/super_images_convnext_lr3e-3/convnext_base_fold0/history.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fonction de perte : passage de BCE à ASL\n",
        "\n",
        "Initialement, la baseline utilisait une perte BCEWithLogitsLoss classique, bien adaptée à la classification multi-label mais peu robuste au fort déséquilibre de classes du dataset QV Pipe (beaucoup de zéros, peu de positives par classe)."
      ],
      "metadata": {
        "id": "GCsklQnZ-gIw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xowCCF82Fs7T"
      }
    }
  ]
}